{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/news.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Quelle</th>\n",
       "      <th>Autor</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_data</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>origin</th>\n",
       "      <th>Autor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.10.2020</td>\n",
       "      <td>Steirische Unis bauen trotz Coronakrise aus</td>\n",
       "      <td>Und das sind die wichtigsten Projekte, die akt...</td>\n",
       "      <td>https://www.krone.at/2259121</td>\n",
       "      <td>Krone</td>\n",
       "      <td>Jörg Schwaiger</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>wichtigsten projekt aktuel graz leoben laufen ...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.12.2020</td>\n",
       "      <td>Immer mehr Firmen verlassen das Silicon Valley</td>\n",
       "      <td>Dort habe das Unternehmen bereits seinen größt...</td>\n",
       "      <td>https://www.krone.at/2297846</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>unternehmen bereit größten beschäftigungsschwe...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07.12.2020</td>\n",
       "      <td>Top-Waffenproduzenten nahmen fast 300 Mrd. € ein</td>\n",
       "      <td>Bei zwölf der 25 größten Rüstungskonzerne hand...</td>\n",
       "      <td>https://www.krone.at/2292763</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>zwölf größten rüstungskonzern handelt unterneh...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2021</td>\n",
       "      <td>Corona: Israel hat schon 1 Million Bürger geimpft</td>\n",
       "      <td>Eine Grafik auf der Website „Our World in Data...</td>\n",
       "      <td>https://www.krone.at/2309676</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>grafik websit „our world data“ vergleicht vers...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.12.2020</td>\n",
       "      <td>Firmen informieren oft nicht über Mitarbeiterd...</td>\n",
       "      <td>Während nur rund die Hälfte der Unternehmen ih...</td>\n",
       "      <td>https://www.krone.at/2298543</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>rund hälfte unternehmen mitarbeit speicherung ...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum                                              Titel  \\\n",
       "0  23.10.2020        Steirische Unis bauen trotz Coronakrise aus   \n",
       "1  14.12.2020     Immer mehr Firmen verlassen das Silicon Valley   \n",
       "2  07.12.2020   Top-Waffenproduzenten nahmen fast 300 Mrd. € ein   \n",
       "3  01.01.2021  Corona: Israel hat schon 1 Million Bürger geimpft   \n",
       "4  15.12.2020  Firmen informieren oft nicht über Mitarbeiterd...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Und das sind die wichtigsten Projekte, die akt...   \n",
       "1  Dort habe das Unternehmen bereits seinen größt...   \n",
       "2  Bei zwölf der 25 größten Rüstungskonzerne hand...   \n",
       "3  Eine Grafik auf der Website „Our World in Data...   \n",
       "4  Während nur rund die Hälfte der Unternehmen ih...   \n",
       "\n",
       "                           Link Quelle           Autor  count_words  \\\n",
       "0  https://www.krone.at/2259121  Krone  Jörg Schwaiger          356   \n",
       "1  https://www.krone.at/2297846  Krone             NaN          199   \n",
       "2  https://www.krone.at/2292763  Krone             NaN          257   \n",
       "3  https://www.krone.at/2309676  Krone             NaN          336   \n",
       "4  https://www.krone.at/2298543  Krone             NaN          142   \n",
       "\n",
       "   count_data  count_capital_words  \\\n",
       "0           0                    4   \n",
       "1           0                    2   \n",
       "2           0                    8   \n",
       "3           0                    1   \n",
       "4           0                    3   \n",
       "\n",
       "                                        cleaned_text   origin Autor   \n",
       "0  wichtigsten projekt aktuel graz leoben laufen ...  Austria    NaN  \n",
       "1  unternehmen bereit größten beschäftigungsschwe...  Austria    NaN  \n",
       "2  zwölf größten rüstungskonzern handelt unterneh...  Austria    NaN  \n",
       "3  grafik websit „our world data“ vergleicht vers...  Austria    NaN  \n",
       "4  rund hälfte unternehmen mitarbeit speicherung ...  Austria    NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('german')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/retoheller/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if type(data[\"cleaned_text\"][i]) == float:\n",
    "        tokens.append([\"no\"])\n",
    "    else:\n",
    "        tokens.append(word_tokenize(data[\"cleaned_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_title = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if type(data[\"Titel\"][i]) == float:\n",
    "        tokens_title.append([\"no\"])\n",
    "    else:\n",
    "        tokens_title.append(word_tokenize(data[\"Titel\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tokens\"] = tokens\n",
    "data[\"tokens_title\"] = tokens_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    token = tokens[i]\n",
    "    for w in token:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "            \n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_size = len(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = [x for x in DF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\n",
    "N = len(data)\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = data[\"tokens\"][i]\n",
    "    \n",
    "    counter = Counter(tokens + data[\"tokens_title\"][i])\n",
    "    words_count = len(tokens + data[\"tokens_title\"][i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\n",
    "\n",
    "tf_idf_title = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = data[\"tokens_title\"][i]\n",
    "    counter = Counter(tokens + data[\"tokens\"][i])\n",
    "    words_count = len(tokens + data[\"tokens\"][i])\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1)) #numerator is added 1 to avoid negative values\n",
    "        \n",
    "        tf_idf_title[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Text\"][249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
