{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/news.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Quelle</th>\n",
       "      <th>Autor</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_data</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>origin</th>\n",
       "      <th>Autor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.10.2020</td>\n",
       "      <td>Steirische Unis bauen trotz Coronakrise aus</td>\n",
       "      <td>Und das sind die wichtigsten Projekte, die akt...</td>\n",
       "      <td>https://www.krone.at/2259121</td>\n",
       "      <td>Krone</td>\n",
       "      <td>Jörg Schwaiger</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>wichtigsten projekt aktuel graz leoben laufen ...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.12.2020</td>\n",
       "      <td>Immer mehr Firmen verlassen das Silicon Valley</td>\n",
       "      <td>Dort habe das Unternehmen bereits seinen größt...</td>\n",
       "      <td>https://www.krone.at/2297846</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>unternehmen bereit größten beschäftigungsschwe...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07.12.2020</td>\n",
       "      <td>Top-Waffenproduzenten nahmen fast 300 Mrd. € ein</td>\n",
       "      <td>Bei zwölf der 25 größten Rüstungskonzerne hand...</td>\n",
       "      <td>https://www.krone.at/2292763</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>zwölf größten rüstungskonzern handelt unterneh...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2021</td>\n",
       "      <td>Corona: Israel hat schon 1 Million Bürger geimpft</td>\n",
       "      <td>Eine Grafik auf der Website „Our World in Data...</td>\n",
       "      <td>https://www.krone.at/2309676</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>grafik websit „our world data“ vergleicht vers...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.12.2020</td>\n",
       "      <td>Firmen informieren oft nicht über Mitarbeiterd...</td>\n",
       "      <td>Während nur rund die Hälfte der Unternehmen ih...</td>\n",
       "      <td>https://www.krone.at/2298543</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>rund hälfte unternehmen mitarbeit speicherung ...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum                                              Titel  \\\n",
       "0  23.10.2020        Steirische Unis bauen trotz Coronakrise aus   \n",
       "1  14.12.2020     Immer mehr Firmen verlassen das Silicon Valley   \n",
       "2  07.12.2020   Top-Waffenproduzenten nahmen fast 300 Mrd. € ein   \n",
       "3  01.01.2021  Corona: Israel hat schon 1 Million Bürger geimpft   \n",
       "4  15.12.2020  Firmen informieren oft nicht über Mitarbeiterd...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Und das sind die wichtigsten Projekte, die akt...   \n",
       "1  Dort habe das Unternehmen bereits seinen größt...   \n",
       "2  Bei zwölf der 25 größten Rüstungskonzerne hand...   \n",
       "3  Eine Grafik auf der Website „Our World in Data...   \n",
       "4  Während nur rund die Hälfte der Unternehmen ih...   \n",
       "\n",
       "                           Link Quelle           Autor  count_words  \\\n",
       "0  https://www.krone.at/2259121  Krone  Jörg Schwaiger          356   \n",
       "1  https://www.krone.at/2297846  Krone             NaN          199   \n",
       "2  https://www.krone.at/2292763  Krone             NaN          257   \n",
       "3  https://www.krone.at/2309676  Krone             NaN          336   \n",
       "4  https://www.krone.at/2298543  Krone             NaN          142   \n",
       "\n",
       "   count_data  count_capital_words  \\\n",
       "0           0                    4   \n",
       "1           0                    2   \n",
       "2           0                    8   \n",
       "3           0                    1   \n",
       "4           0                    3   \n",
       "\n",
       "                                        cleaned_text   origin Autor   \n",
       "0  wichtigsten projekt aktuel graz leoben laufen ...  Austria    NaN  \n",
       "1  unternehmen bereit größten beschäftigungsschwe...  Austria    NaN  \n",
       "2  zwölf größten rüstungskonzern handelt unterneh...  Austria    NaN  \n",
       "3  grafik websit „our world data“ vergleicht vers...  Austria    NaN  \n",
       "4  rund hälfte unternehmen mitarbeit speicherung ...  Austria    NaN  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('german')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/retoheller/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if type(data[\"cleaned_text\"][i]) == float:\n",
    "        tokens.append([\"no\"])\n",
    "    else:\n",
    "        tokens.append(word_tokenize(data[\"cleaned_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_title = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if type(data[\"Titel\"][i]) == float:\n",
    "        tokens_title.append([\"no\"])\n",
    "    else:\n",
    "        tokens_title.append(word_tokenize(data[\"Titel\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinzufügen der Token des Textes und des Titels zum Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tokens\"] = tokens\n",
    "data[\"tokens_title\"] = tokens_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    token = tokens[i]\n",
    "    for w in token:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "            \n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totales Vokabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_size = len(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = [x for x in DF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Doc Frequency\n",
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF für den Text Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\n",
    "N = len(data)\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = data[\"tokens\"][i]\n",
    "    \n",
    "    counter = Counter(tokens + data[\"tokens_title\"][i])\n",
    "    words_count = len(tokens + data[\"tokens_title\"][i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF für den Titel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\n",
    "\n",
    "tf_idf_title = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = data[\"tokens_title\"][i]\n",
    "    counter = Counter(tokens + data[\"tokens\"][i])\n",
    "    words_count = len(tokens + data[\"tokens\"][i])\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1)) #numerator is added 1 to avoid negative values\n",
    "        \n",
    "        tf_idf_title[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha\n",
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TF-IDF Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_idf:\n",
    "    tf_idf[i] *= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_idf_title:\n",
    "    tf_idf[i] = tf_idf_title[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Top 5 Key Words per Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_total = []\n",
    "token_total = []\n",
    "docs_total = []\n",
    "\n",
    "for i in range(len(data[\"cleaned_text\"])):\n",
    "    values=[]\n",
    "    document=[]\n",
    "    token = []\n",
    "    for key in tf_idf:\n",
    "        if key[0] == i:\n",
    "            document.append(key[0])\n",
    "            values.append(key[1])\n",
    "            token.append(tf_idf[key])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    df = pd.DataFrame()\n",
    "    df[\"values\"] = values\n",
    "    df[\"token\"] = token\n",
    "    df[\"doc\"] = document\n",
    "    df = df.sort_values(by='token', ascending=False)\n",
    "    df = df.head()\n",
    "    values_total.append(df[\"values\"].to_list())\n",
    "    token_total.append(df[\"token\"].to_list())\n",
    "    docs_total.append(df[\"doc\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_ = []\n",
    "values_1 = []\n",
    "values_2 = []\n",
    "values_3 = []\n",
    "values_4 = []\n",
    "values_5 = []\n",
    "\n",
    "for i in range(len(values_total)):\n",
    "    if len(values_total[i]) == 5:\n",
    "        values_1.append(values_total[i][0])\n",
    "        values_2.append(values_total[i][1])\n",
    "        values_3.append(values_total[i][2])\n",
    "        values_4.append(values_total[i][3])\n",
    "        values_5.append(values_total[i][4])\n",
    "    else:\n",
    "        values_1.append(values_total[i][0])\n",
    "        values_2.append(\"\")\n",
    "        values_3.append(\"\")\n",
    "        values_4.append(\"\")\n",
    "        values_5.append(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spalten der Key Words zum Dataframe hinzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"key_word1\"] = values_1\n",
    "data[\"key_word2\"] = values_2\n",
    "data[\"key_word3\"] = values_3\n",
    "data[\"key_word4\"] = values_4\n",
    "data[\"key_word5\"] = values_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Quelle</th>\n",
       "      <th>Autor</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_data</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>origin</th>\n",
       "      <th>Autor</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_title</th>\n",
       "      <th>key_word1</th>\n",
       "      <th>key_word2</th>\n",
       "      <th>key_word3</th>\n",
       "      <th>key_word4</th>\n",
       "      <th>key_word5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.10.2020</td>\n",
       "      <td>Steirische Unis bauen trotz Coronakrise aus</td>\n",
       "      <td>Und das sind die wichtigsten Projekte, die akt...</td>\n",
       "      <td>https://www.krone.at/2259121</td>\n",
       "      <td>Krone</td>\n",
       "      <td>Jörg Schwaiger</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>wichtigsten projekt aktuel graz leoben laufen ...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[wichtigsten, projekt, aktuel, graz, leoben, l...</td>\n",
       "      <td>[Steirische, Unis, bauen, trotz, Coronakrise, ...</td>\n",
       "      <td>graz</td>\n",
       "      <td>Unis</td>\n",
       "      <td>Steirische</td>\n",
       "      <td>Coronakrise</td>\n",
       "      <td>leoben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.12.2020</td>\n",
       "      <td>Immer mehr Firmen verlassen das Silicon Valley</td>\n",
       "      <td>Dort habe das Unternehmen bereits seinen größt...</td>\n",
       "      <td>https://www.krone.at/2297846</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>unternehmen bereit größten beschäftigungsschwe...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[unternehmen, bereit, größten, beschäftigungss...</td>\n",
       "      <td>[Immer, mehr, Firmen, verlassen, das, Silicon,...</td>\n",
       "      <td>Firmen</td>\n",
       "      <td>Valley</td>\n",
       "      <td>Silicon</td>\n",
       "      <td>Immer</td>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07.12.2020</td>\n",
       "      <td>Top-Waffenproduzenten nahmen fast 300 Mrd. € ein</td>\n",
       "      <td>Bei zwölf der 25 größten Rüstungskonzerne hand...</td>\n",
       "      <td>https://www.krone.at/2292763</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>zwölf größten rüstungskonzern handelt unterneh...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[zwölf, größten, rüstungskonzern, handelt, unt...</td>\n",
       "      <td>[Top-Waffenproduzenten, nahmen, fast, 300, Mrd...</td>\n",
       "      <td>nahmen</td>\n",
       "      <td>€</td>\n",
       "      <td>Top-Waffenproduzenten</td>\n",
       "      <td>Mrd</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2021</td>\n",
       "      <td>Corona: Israel hat schon 1 Million Bürger geimpft</td>\n",
       "      <td>Eine Grafik auf der Website „Our World in Data...</td>\n",
       "      <td>https://www.krone.at/2309676</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>grafik websit „our world data“ vergleicht vers...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[grafik, websit, „, our, world, data, “, vergl...</td>\n",
       "      <td>[Corona, :, Israel, hat, schon, 1, Million, Bü...</td>\n",
       "      <td>israel</td>\n",
       "      <td>:</td>\n",
       "      <td>Million</td>\n",
       "      <td>Bürger</td>\n",
       "      <td>Corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.12.2020</td>\n",
       "      <td>Firmen informieren oft nicht über Mitarbeiterd...</td>\n",
       "      <td>Während nur rund die Hälfte der Unternehmen ih...</td>\n",
       "      <td>https://www.krone.at/2298543</td>\n",
       "      <td>Krone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>rund hälfte unternehmen mitarbeit speicherung ...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[rund, hälfte, unternehmen, mitarbeit, speiche...</td>\n",
       "      <td>[Firmen, informieren, oft, nicht, über, Mitarb...</td>\n",
       "      <td>Mitarbeiterdaten</td>\n",
       "      <td>Firmen</td>\n",
       "      <td>über</td>\n",
       "      <td>betriebsvereinbarungen</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datum                                              Titel  \\\n",
       "0  23.10.2020        Steirische Unis bauen trotz Coronakrise aus   \n",
       "1  14.12.2020     Immer mehr Firmen verlassen das Silicon Valley   \n",
       "2  07.12.2020   Top-Waffenproduzenten nahmen fast 300 Mrd. € ein   \n",
       "3  01.01.2021  Corona: Israel hat schon 1 Million Bürger geimpft   \n",
       "4  15.12.2020  Firmen informieren oft nicht über Mitarbeiterd...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Und das sind die wichtigsten Projekte, die akt...   \n",
       "1  Dort habe das Unternehmen bereits seinen größt...   \n",
       "2  Bei zwölf der 25 größten Rüstungskonzerne hand...   \n",
       "3  Eine Grafik auf der Website „Our World in Data...   \n",
       "4  Während nur rund die Hälfte der Unternehmen ih...   \n",
       "\n",
       "                           Link Quelle           Autor  count_words  \\\n",
       "0  https://www.krone.at/2259121  Krone  Jörg Schwaiger          356   \n",
       "1  https://www.krone.at/2297846  Krone             NaN          199   \n",
       "2  https://www.krone.at/2292763  Krone             NaN          257   \n",
       "3  https://www.krone.at/2309676  Krone             NaN          336   \n",
       "4  https://www.krone.at/2298543  Krone             NaN          142   \n",
       "\n",
       "   count_data  count_capital_words  \\\n",
       "0           0                    4   \n",
       "1           0                    2   \n",
       "2           0                    8   \n",
       "3           0                    1   \n",
       "4           0                    3   \n",
       "\n",
       "                                        cleaned_text   origin Autor   \\\n",
       "0  wichtigsten projekt aktuel graz leoben laufen ...  Austria    NaN   \n",
       "1  unternehmen bereit größten beschäftigungsschwe...  Austria    NaN   \n",
       "2  zwölf größten rüstungskonzern handelt unterneh...  Austria    NaN   \n",
       "3  grafik websit „our world data“ vergleicht vers...  Austria    NaN   \n",
       "4  rund hälfte unternehmen mitarbeit speicherung ...  Austria    NaN   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [wichtigsten, projekt, aktuel, graz, leoben, l...   \n",
       "1  [unternehmen, bereit, größten, beschäftigungss...   \n",
       "2  [zwölf, größten, rüstungskonzern, handelt, unt...   \n",
       "3  [grafik, websit, „, our, world, data, “, vergl...   \n",
       "4  [rund, hälfte, unternehmen, mitarbeit, speiche...   \n",
       "\n",
       "                                        tokens_title         key_word1  \\\n",
       "0  [Steirische, Unis, bauen, trotz, Coronakrise, ...              graz   \n",
       "1  [Immer, mehr, Firmen, verlassen, das, Silicon,...            Firmen   \n",
       "2  [Top-Waffenproduzenten, nahmen, fast, 300, Mrd...            nahmen   \n",
       "3  [Corona, :, Israel, hat, schon, 1, Million, Bü...            israel   \n",
       "4  [Firmen, informieren, oft, nicht, über, Mitarb...  Mitarbeiterdaten   \n",
       "\n",
       "  key_word2              key_word3               key_word4 key_word5  \n",
       "0      Unis             Steirische             Coronakrise    leoben  \n",
       "1    Valley                Silicon                   Immer       das  \n",
       "2         €  Top-Waffenproduzenten                     Mrd       300  \n",
       "3         :                Million                  Bürger    Corona  \n",
       "4    Firmen                   über  betriebsvereinbarungen        ak  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking using Matching Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score\n",
      "\n",
      "Query: Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\n",
      "\n",
      "['without', 'the', 'drive', 'of', 'rebeccah', 'insist', 'kate', 'lost', 'her', 'momentum', 'she', 'stood', 'next', 'slat', 'oak', 'bench', 'canist', 'still', 'clutch', 'survey']\n",
      "\n",
      "[345, 184, 362, 514, 175, 495, 961, 333, 8, 57]\n"
     ]
    }
   ],
   "source": [
    "def matching_score(k, query):\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "\n",
    "    print(\"Matching Score\")\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    query_weights = {}\n",
    "\n",
    "    for key in tf_idf:\n",
    "        \n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for i in query_weights[:10]:\n",
    "        l.append(i[0])\n",
    "    \n",
    "    print(l)\n",
    "    \n",
    "\n",
    "matching_score(10, \"Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((N, total_vocab_size))\n",
    "for i in tf_idf:\n",
    "    try:\n",
    "        ind = total_vocab.index(i[1])\n",
    "        D[i[0]][ind] = tf_idf[i]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector(tokens):\n",
    "\n",
    "    Q = np.zeros((len(total_vocab)))\n",
    "    \n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    query_weights = {}\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = math.log((N+1)/(df+1))\n",
    "\n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "\n",
      "Query: Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\n",
      "\n",
      "['without', 'the', 'drive', 'of', 'rebeccah', 'insist', 'kate', 'lost', 'her', 'momentum', 'she', 'stood', 'next', 'slat', 'oak', 'bench', 'canist', 'still', 'clutch', 'survey']\n",
      "\n",
      "[ 184  362  345  619  961  514  175  895 1003  542]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(k, query):\n",
    "    print(\"Cosine Similarity\")\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    \n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    d_cosines = []\n",
    "    \n",
    "    query_vector = gen_vector(tokens)\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "        \n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    print(out)\n",
    "\n",
    "#     for i in out:\n",
    "#         print(i, dataset[i][0])\n",
    "\n",
    "Q = cosine_similarity(10, \"Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
