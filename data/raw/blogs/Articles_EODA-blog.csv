Datum;Titel;Text;Link;Quelle;Autor
04.03.2020;Wie sich Shiny® und YUNA gegenseitig ergänzen;, ×, YUNA, YUNA, Vorname*, Nachname*, E-Mail*, Telefon*, Organisation*,  - Beitrag vom 04.03.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/wie-shiny-yuna-ergaenzen;EODA;
30.01.2020;Shiny: Load Testing und Horizontale Skalierung ;", ×, Shiny:, Architektur, Load-Testing-Tools &amp; Testanwendung, function, 2, 1000, 1, darkgray, white, Im Sessions-Tab können die von den, Im Sessions-Tab können die von den, Workern, Workern, gestarteten Sessions analysiert, gestarteten Sessions analysiert, werden. In unserem Beispiel schafft jeder, werden. In unserem Beispiel schafft jeder, Worker, Worker, ca. 3-4 Sessions während des von uns gewählten Zeitraums von zwei Minuten. Die Breite der Blöcke spiegelt dabei die benötigte Berechnungszeit wider, die jeder Schritt in der von uns aufgezeichneten Session benötigt., ca. 3-4 Sessions während des von uns gewählten Zeitraums von zwei Minuten. Die Breite der Blöcke spiegelt dabei die benötigte Berechnungszeit wider, die jeder Schritt in der von uns aufgezeichneten Session benötigt., , Bei einer Anzahl von, Bei einer Anzahl von, Workern, Workern,  &gt; 300 fallen zuerst breiter werdende Blöcke auf. Außerdem lassen sich zum ersten Mal signifikant breite türkise und gelbe Blöcke erkennen, welche den Start der Sessions und das Laden der JS/CSS-Files beschreiben. ,  &gt; 300 fallen zuerst breiter werdende Blöcke auf. Außerdem lassen sich zum ersten Mal signifikant breite türkise und gelbe Blöcke erkennen, welche den Start der Sessions und das Laden der JS/CSS-Files beschreiben. , Im Session Duration-Tab findet sich jede gestartete Session von allenWorkernder Ausführungszeit, Im Session Duration-Tab findet sich jede gestartete Session von allen, Workern, der Ausführungszeit, nach, nach, aufsteigend sortiert, aufsteigend sortiert, ., ., , Bei einer Anzahl vonWorkern&gt; 200 zeichnet sich ca. ab dem letzten Drittel der Sessions eine deutliche Steigerung der Ausführungszeit ab., Bei einer Anzahl von, Workern, &gt; 200 zeichnet sich ca. ab dem letzten Drittel der Sessions eine deutliche Steigerung der Ausführungszeit ab.,  , Im Event-, Im Event-, Waterfall, Waterfall, -Tab wird die aufgezeichnete Session in, -Tab wird die aufgezeichnete Session in, ihre einzelnen Events unterteilt (bspw. Anpassen des Histogramms – Neuzeichnung des Plots, …). Jede gestartete Session, ihre einzelnen Events unterteilt (bspw. Anpassen des Histogramms – Neuzeichnung des Plots, …). Jede gestartete Session, durchläuft als Linie von oben bis unten alle Events und wird anhand der verstrichenen Zeit gezeichnet. Verlaufen die Linien von zwei gestarteten Sessions parallel, benötigen sie dieselbe Zeit, um die aufgezeichnete Session auszuführen., durchläuft als Linie von oben bis unten alle Events und wird anhand der verstrichenen Zeit gezeichnet. Verlaufen die Linien von zwei gestarteten Sessions parallel, benötigen sie dieselbe Zeit, um die aufgezeichnete Session auszuführen., , Bei einer Anzahl von, Bei einer Anzahl von, Workern, Workern, &gt; 200 beginnen sich Unregelmäßigkeiten in der Parallelität der Linien abzuzeichnen, &gt; 200 beginnen sich Unregelmäßigkeiten in der Parallelität der Linien abzuzeichnen, , sodass Sessions ab einem gewissen Zeitraum eine stärkere Tendenz nach rechts aufweisen., , sodass Sessions ab einem gewissen Zeitraum eine stärkere Tendenz nach rechts aufweisen.,  , Im, Im, Latency, Latency, -Tab wird für jede Session die Zeit dargestellt, die für HTTP-Anfragen und das Laden der JS/CSS-Dateien benötigt wird. Die rote Linie sy, -Tab wird für jede Session die Zeit dargestellt, die für HTTP-Anfragen und das Laden der JS/CSS-Dateien benötigt wird. Die rote Linie sy, mbolisiert dabei einen Referenzwert von 5 Sekunden, an dem die Verteilung der Ladezeiten gemessen werden kann (Hier nicht gezeigt ist der zweite Reiter des Tabs, in dem die Reaktionszeit von, mbolisiert dabei einen Referenzwert von 5 Sekunden, an dem die Verteilung der Ladezeiten gemessen werden kann (Hier nicht gezeigt ist der zweite Reiter des Tabs, in dem die Reaktionszeit von, Shiny, Shiny, für Berechnungen gemessen und äquivalent dargestellt wird), für Berechnungen gemessen und äquivalent dargestellt wird), ., ., , Bei einer Anzahl vonWorkern&gt; 200 überschreiten die ersten Sessions den gesetzten Referenzwert. Bei einer, Bei einer Anzahl von, Workern, &gt; 200 überschreiten die ersten Sessions den gesetzten Referenzwert. Bei einer, Anzahl vonWorkern&gt; 400 machen sich zum ersten Mal die Ladezeiten der JS/CSS-Dateien deutlich bemerkbar., Anzahl von, Workern, &gt; 400 machen sich zum ersten Mal die Ladezeiten der JS/CSS-Dateien deutlich bemerkbar., , Im Event-Duration-Tab wird für jeden Lauf ein Boxplot für jedes einzelne Event dargestellt, absteigend geordnet nach der längsten gemessenen Zeit., Im Event-Duration-Tab wird für jeden Lauf ein Boxplot für jedes einzelne Event dargestellt, absteigend geordnet nach der längsten gemessenen Zeit., , Bei ein, Bei ein, er Anzahl vonWorkern&gt; 400 enthalten die Boxplots zum ersten Mal über die meisten Events hinweg konsistent Ausreißer. Ferner finden sich erst hier für viele Events signifikante Ladezeiten, welche bei den Läufen mit wenigerWorkernkaum ins Gewicht fallen., er Anzahl von, Workern, &gt; 400 enthalten die Boxplots zum ersten Mal über die meisten Events hinweg konsistent Ausreißer. Ferner finden sich erst hier für viele Events signifikante Ladezeiten, welche bei den Läufen mit weniger, Workern, kaum ins Gewicht fallen., , Im Event-, Im Event-, Concurrency, Concurrency, -Tab wird für jeden Lauf ein Scatterplot für jedes Event dargestellt, basierend auf der Anzahl gleichzeitiger Nutzer. Für jeden Lauf wird eine Regressionsgerade an den Plot angepasst und dann absteigend nach größter, -Tab wird für jeden Lauf ein Scatterplot für jedes Event dargestellt, basierend auf der Anzahl gleichzeitiger Nutzer. Für jeden Lauf wird eine Regressionsgerade an den Plot angepasst und dann absteigend nach größter, gemessener Steigung der Geraden sortiert (In den anderen Reitern wird nach größtem gemessenen Achsenabschnitt/größtem gemessenen Fehler sortiert. Außerdem lassen sich die Ergebnisse der Regressionsmodelle in einer Tabelle abrufen), gemessener Steigung der Geraden sortiert (In den anderen Reitern wird nach größtem gemessenen Achsenabschnitt/größtem gemessenen Fehler sortiert. Außerdem lassen sich die Ergebnisse der Regressionsmodelle in einer Tabelle abrufen), ., ., Bei einer Anzahl vonWorkern&gt; 300, Bei einer Anzahl von, Workern, &gt; 300, zeichnet sich zum ersten Mal eine breitere Verteilung der Punkte im Scatterplot ab. Die Anzahl der gleichzeitig aktiven Nutzer tendiert aufgrund von höheren Ladezeiten in Richtung 250 – 300. Bei einer Anzahl vonWorkern&gt; 400 vergrößert sich dieses Intervall, zeichnet sich zum ersten Mal eine breitere Verteilung der Punkte im Scatterplot ab. Die Anzahl der gleichzeitig aktiven Nutzer tendiert aufgrund von höheren Ladezeiten in Richtung 250 – 300. Bei einer Anzahl von, Workern, &gt; 400 vergrößert sich dieses Intervall, wie zu erwarten auf, wie zu erwarten auf, 250 – 400 gleichzeitig aktive Nutzer, 250 – 400 gleichzeitig aktive Nutzer, ., .,  - Beitrag vom 30.01.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/shiny-load-testing-und-horizontale-skalierung;EODA;
22.01.2020;Die 5 Data Science Trends 2020;, ×, Data Science Trends 2020, Wir verwandeln Trendthemen für Sie in nachhaltige Mehrwerte,  - Beitrag vom 22.01.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/die-5-data-science-trends-2020;EODA;
22.01.2020;Schön‘ juten Tach und Moin Moin: R-Trainings in Berlin und Hamburg;, ×, R-Trainings, Berlin, Hamburg, R ist eine der führenden Programmiersprachen für Datenanalyse und Datenvisualisierung. , Erschließen Sie, in unseren beliebten R-Trainings, das Potenzial von Data Science, und lernen Sie, wie Sie mit der Open-Source-Sprache Daten in Mehrwerte verwandeln können., Mit über 1.500 zufriedenen Teilnehmern gehören die R-, Trainings, von eoda zu den Führenden im deutschsprachigen Raum., , Im April 2020 und Oktober 2020 ist es soweit: Wir bringen unsere beliebten Trainings, „Einführung in R“ und „Machine Learning mit R“, nach Berlin und Hamburg., , Kursinhalte, Einführung in R, Mit praktischen Tipps und Übungen dient dieser Einführungskurs als Grundlage für den weiteren Einsatz von R in individuellen Anwendungsfällen. Um die Basis für ein selbstständiges Arbeiten legen zu können, steht die Vermittlung der Logik und Terminologie von R im Vordergrund. Dieser Kurs richtet sich an Einsteiger und setzt somit keine tiefergehenden Vorkenntnisse voraus., , Machine Learning mit R, Nutzen Sie Machine Learning und Data-Mining-Algorithmen, um auf Datenbasis Anwendungen der Künstlichen Intelligenz zu entwickeln., Erfahren Sie, ebenfalls,, welche Herausforderungen Ihnen begegnen und wie Sie diese mit R meistern können., , , Mittels praxisnaher Beispiele und praktischer Übungen vermitteln wir Ihnen in diesem Kurs die Fähigkeiten, um Machine-Learning-Verfahren in R eigenständig durchzuführen., , , Berlin, , Einführung in R, , 21.04. – 22.04.2020, |, Machine Learning mit R, , 23.04. – 24.04.2020, , Hamburg, , Einführung in R, , 13.10. – 14.10.2020, |, Machine Learning mit R, , 15.10. – 16.10.2020, , Diese beiden Einführungskurse können auch als Bundle zu einem attraktiven Angebotspreis gebucht werden., , , Sichern Sie sich einen der begehrten Plätze und werden Sie, dieses Jahr,  zum Data Science Experten mit R! Wir freuen uns auf Ihre Anmeldung. Hier finden Sie mehr zu den Trainings: Berlin und Hamburg., Mehr noch: In unseren Python-Trainings, geben wir Ihnen, ebenfalls, einen praxisnahen Einblick in den Funktionsumfang der Universalsprache, im Data-Science-Kontext, ., Sprechen Sie uns an!,  - Beitrag vom 22.01.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/r-trainings-in-hamburg-berlin;EODA;
16.01.2020;"""Data Science"" im Marketing - Eat your own dogfood";, ×, Vorname*, Nachname*, E-Mail*, Telefon*, Organisation*,  - Beitrag vom 16.01.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-platform-marketing;EODA;
10.01.2020;Data Science und KI: Konferenzen 2020;, ×, Data Science und KI:,  - Beitrag vom 10.01.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/ki-konferenzen-2020;EODA;
15.12.2019;So baut man Data Science Plattformen - Teil 5: Datenvisualisierung und belastbare Ergebnisse;, ×, Data Science Plattformen,  - Beitrag vom 15.12.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/so-baut-man-analytikplattformen-teil-5-datenvisualisierung-und-belastbare-ergebnisse;EODA;
11.12.2019;Datenstrategie: Wegweiser zu digitalen Erfolgen;, ×, Datenstrategie,  - Beitrag vom 11.12.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-strategie-wegweiser;EODA;
10.12.2019;So baut man Data Science Plattformen - Teil 4: Datenbankskalierbarkeit und Business Models;, ×, Data Science Plattformen,  - Beitrag vom 10.12.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/how-to-analytikplattformen-datenquellen-geschaeftsmodelle-usecase;EODA;
08.12.2019;So baut man Data Science Plattformen - ;, ×, Data Science Plattformen,  - Beitrag vom 08.12.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/how-to-analytikplattformen-workflows-dashboards;EODA;
06.12.2019;So baut man Data Science Plattformen - Teil 2: Intelligentes Benutzer- und Rollenkonzept;, ×, Data Science Plattformen,  - Beitrag vom 06.12.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/how-to-analytikplattformen-berechtigungen-benutzerrollen;EODA;
03.12.2019;So baut man Data Science Plattformen - Teil 1: UI und Teams;, ×, Data Science Plattformen, Lesezeit: ca. 2min.,  - Beitrag vom 03.12.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/how-to-analytikplattformen-teil-1-ui-teams-2;EODA;
28.11.2019;Versionsverwaltung – Die unkomplizierte Arbeit am gemeinsamen Projekt ;, ×, Versionsverwaltung, Wer im, Jahr, 2019 einen Job als Entwickler antritt, sei es in der Softwareentwicklung oder im Bereich Data Science, Data-Ops, etc., der wird zu meist relativ früh mit einem Tool zur Versionsverwaltung konfrontiert. Programme wieGit, SVN undBitKeeper, werden primär verwendet, um die Entwicklungshistorie transparent vor- und, zurückzuspulen, oder neue Features auf, separaten,  Entwicklungszweigen zu entwickeln, ., Außerdem, zeichnet sich, die Versionskontrolle, für, die, lineare Skriptentwicklung, und das Code Management, aus, ., Auch wenn das zum Einstieg benötigte Vokabular vergleichsweise gering erscheint, so sollte man sich davon nicht täuschen lassen, ., Für Personen, ,, die zum ersten Mal mit, diesen Tools, arbeiten,, erfordert das, Einsteigen, , ein ungewohntes Denken beim Anwenden., , Um, produktiv, mit den Tools, arbeiten, zu, können, ,, reich, t, zum, Einstieg, eine Handvoll, , Vokab, eln, ,, um einen, transparenten und, konfliktfreien, A, r, beitsablauf, , gewährleisten, zu, können., , Neben den gängigen, Befehlen, bieten alle Tools eine, große, Funktionsvielfalt, ,, , die, für spezifische Anwendungsfälle, hilfreich sind, aber auch die Komplexität der, Arbeitsablaufs, erhöh, en, ., , In diesem Artikel, geben, wir, zum einen, eine kurze Einführung in die Aufgaben einer Software zur Versionsverwaltung, und zum, anderen wird eines dieser, Tools genauer betrachtet., , Protokollieren, Archivieren, Die grundlegende Arbeitsweise der Versionsverwaltungstools ist recht simpel. In dem Einstiegspunkt, einem, (Projekt-), Ordner, werden Änderungen an, den, Dateien, verfolgt, ., , Es werden grundsätzlich nicht alle Dateien auf Änderungen überwacht, sondern nur Dateien die, vom Benutzer, vorgemerkt oder indexiert sind., Zusätzlich können Dateien explizit auf Entwicklun, g, szweigen, vorgemerkt, und somit isoliert entwickelt, werden, . D, ieses Vorgehen, vermeidet Konflikte, , da die anderen Nutzer, erst, das fertige, , Feature, zu, sehen, bekommen, und sich, auf die Entwicklung von ihren, Eigenen, konzentrieren können, ,, ohne Rücksicht auf potenzielle Änderungen zu nehmen., Somit können jederzeit unterschiedliche Entwicklungsstände des Projektes abgerufen und bei Bedarf widerhergestellt werden., , Der, Workflow, kann sich dabei, wie ein Baum vorgestellt , werden., Dieser ist projektübergreifend meist identisch:, , Alle Dateien samt Versionsbaum werden in einem Projektarchiv (, Repository, ) gespeichert. Der Entwickler klont den aktuellen Stand (der symbolischen Referenz) in sein lokales Arbeitsverzeichnis., , Es existiert ein Hauptzweig, auf dem sich immer eine lauffähige und aktuellste, „live“, Version des Projektes befindet (Trunk – SVN / Master –Git). Neben dem Master gibt es einen, weiteren, Entwicklungszweig „, develop“ (, nightly, , build, ), . Es ist ein zusätzlicher Zweig, der, bestenfalls, (immer), funktionsfähig ist, und die aktuelle, n, , Produktiv-F, eatures, enthält., , , Werden Änderung durchgeführt, so werden diese zunächst auf einem, separaten, , Zweig, (, Branch, ), implementiert, ., Ist der Entwickler mit seinen Änderungen zufrieden,, “, commited, ”, er seine Änderungen,, das, heißt,, er pflegt seine Änderungen in die Versionsverwaltung ein., , Damit andere Entwickler auch auf die neuen lokalen Änderungen zugreifen können, wird der bisher lokale Branch durch einen, “, Push, ”, , in dem Remote Repository publiziert. Auf diesem Weg können die Entwickler ihre Entwicklungsstände synchronisieren., , Ist die Änderung getestet und lauffähig, so kann bei Bedarf der, Entwicklerzweig, mit dem Hauptzweig zusammengeführt werden, (“, merge, ”)., , Git, Im Gegensatz zur zentralen Versionsverwaltung, in der der Versionsbaum nur in einem zentralen Repository vorhanden ist, hat jeder Entwickler in der dezentralen (verteilten) Versionsverwaltung sein eigenes lokales Repository. Änderungen können dabei im eigenen Repository lokal verfolgt und ggf. mit denRepositoriesanderer Entwickler abgeglichen werden. Konflikte bei der Arbeit an denselben Dateien zwischen zwei oder mehr Entwicklern müssen dadurch erst dann gelöst werden, wenn die verschiedenen Versionen zu einer zusammengeführt werden sollen. Im Folgenden soll ein möglicher Workflow mitGitvorgestellt werden, eine der populärsten Applikationen zur dezentralen Versionsverwaltung. Hierbei ist anzumerken, dass wir uns auf eine Variante der verteilten Versionsverwaltung beziehen, in der ein offizielles Repository existiert, welches zu Beginn des Projektes geklont wird undauf dem lokale Änderungenzusammengeführt werden. In der Theorie ist dies nicht zwingend nötig, macht aber in den meisten Projekten Sinn., Im Gegensatz zur zentralen Versionsverwaltung, in der der Versionsbaum nur in einem zentralen Repository vorhanden ist, hat jeder Entwickler in der dezentralen (verteilten) Versionsverwaltung sein eigenes lokales Repository. Änderungen können dabei im eigenen Repository lokal verfolgt und ggf. mit den, Repositories, anderer Entwickler abgeglichen werden. Konflikte bei der Arbeit an denselben Dateien zwischen zwei oder mehr Entwicklern müssen dadurch erst dann gelöst werden, wenn die verschiedenen Versionen zu einer zusammengeführt werden sollen. Im Folgenden soll ein möglicher Workflow mit, Git, vorgestellt werden, eine der populärsten Applikationen zur dezentralen Versionsverwaltung. Hierbei ist anzumerken, dass wir uns auf eine Variante der verteilten Versionsverwaltung beziehen, in der ein offizielles Repository existiert, welches zu Beginn des Projektes geklont wird und, auf dem lokale Änderungen, zusammengeführt werden. In der Theorie ist dies nicht zwingend nötig, macht aber in den meisten Projekten Sinn., , Remote Repositorys, Zunächst wird ein offizielles Repository angelegt, auf dass jeder Entwickler Zugriff hat. In diesem befindet sich ein M, Zunächst wird ein offizielles Repository angelegt, auf dass jeder Entwickler Zugriff hat. In diesem befindet sich ein M, aster-Branch, welche nur dafür da ist, stabile Versionen zur Verfügung zu stellen, welche, aster-Branch, welche nur dafür da ist, stabile Versionen zur Verfügung zu stellen, welche, aus den lokalen Entwicklerversionen zusammengeführt werden. Keiner der Entwickler sollte dabei direkte Änderungen am M, aus den lokalen Entwicklerversionen zusammengeführt werden. Keiner der Entwickler sollte dabei direkte Änderungen am M, aster-Branch vornehmen., aster-Branch vornehmen., , lokalen Branches, Jeder Entwickler erzeugt lokaleBranches, auf denen Features o.Ä. entwickelt werden. Die lokalenBrancheswerden über einen Upstream mit dem Remote Repository synchronisiert., Jeder Entwickler erzeugt lokale, Branches, , auf denen Features o.Ä. entwickelt werden. Die lokalen, Branches, werden über einen Upstream mit dem Remote Repository synchronisiert., , stage/commit/push, Nachdem lokal Veränderungen an Dokumenten/Dateien/Ordnern vorgenommen wurden, müssen diese zunächst “gestaged” werden, was die Änderungen für den nächsten “commit” vormerkt. Nachdem die Änderungen dann durch den “, Nachdem lokal Veränderungen an Dokumenten/Dateien/Ordnern vorgenommen wurden, müssen diese zunächst “, gestaged, ” werden, was die Änderungen für den nächsten “, commit, ” vormerkt. Nachdem die Änderungen dann durch den “, Commit” in den lokalen Branch überführt wurden, wird der Zweig mittels “Push” mit dem Remote Repository synchronisiert., Commit” in den lokalen Branch überführt wurden, wird der Zweig mittels “Push” mit dem Remote Repository synchronisiert., , Entwicklerzweige, Sind alle nötigen Features für eine aktualisierte Version in-place, so können die Entwicklerzweige auf dem Master-Branch zusammengeführt (, Sind alle nötigen Features für eine aktualisierte Version in-place, so können die Entwicklerzweige auf dem Master-Branch zusammengeführt (, merge, merge, ) werden. Hierbei werden potenzielle Konflikte zwischen verschiedenen Branchesaufgelöst., ) werden. Hierbei werden potenzielle Konflikte zwischen verschiedenen , Branches, aufgelöst., , Die Versionsverwaltung stellt ein zentrales Tool für das Projektmanagement dar – nicht nur in der Entwicklerbranche. Die Versionierung von Dokumenten findet beinahe in jedem Bereich Anwendung, wenn auch nicht immer mit Tools wie Git oder SVN (z.B. beim gemeinsamen Arbeiten am Word-Dokument). Mit zahlreichen Zusatzapplikation, welche beispielsweise eine GUI zur Versionsverwaltung anbieten (z.B. GitLab für Git) oder im gleichen Zuge bereits eine vollständige CI-Pipeline für das Repository zur Verfügung stellen (z.B. , ), wird die Arbeit am gemeinsamen Projekt voraussichtlich auch in Zukunft immer einfacher und damit auch zugänglicher werden., , Gern unterstützen wir Sie im Rahmen unsereseoda|analyticinfrastructureconsultingbeim Aufbau einer produktiven Data-Science-Umgebung im Hinblick auf die optimale Versionsverwaltung und viele andere wichtige Aspekte in Ihrem Unternehmen., ,  - Beitrag vom 28.11.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/versionsverwaltung-die-unkomplizierte-arbeit-am-gemeinsamen-projekt;EODA;
28.11.2019;Willkommen zum eoda Data Science Adventskalender;, ×, Adventskalender,  - Beitrag vom 28.11.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-adventskalender;EODA;
21.11.2019;Package Management: Einsatz von Repositories in Produktivsystemen;, ×, Package Management:, Produktivsystemen, Data Science zeichnet sich unter anderem durch das Verwenden von Open Source Tools aus. Ein Vorteil beim Arbeiten mit Open Source Skriptsprachen, Data Science zeichnet sich unter anderem durch das Verwenden von Open Source Tools aus. Ein Vorteil beim Arbeiten mit Open Source Skriptsprachen, , wie z.B., , wie z.B., R oder Python, R oder Python, ,, ,, ist die große Paketwelt, ist die große Paketwelt, . Diese liefert durch die Entwicklung innerhalb riesiger Communities Werkzeuge für zahlreiche Anwendungsfälle und Problemstellungen., . Diese liefert durch die Entwicklung innerhalb riesiger Communities Werkzeuge für zahlreiche Anwendungsfälle und Problemstellungen.,  Dabei sind die Pakete in digitalen Online-Archiven – sogenannten R,  Dabei sind die Pakete in digitalen Online-Archiven – sogenannten R, epositories, epositories, , , – organisiert. Data, – organisiert. Data, Scientists, Scientists, können über diese, können über diese, Repositories, Repositories, auf die aktuellen oder vergangenen Paketversionen zugreifen und diese für ihre Arbeit benutzen. Ein wichtiger Aspekt dabei ist die kontinuierliche Weiterentwicklung vieler Pakete. Neue Paketversionen weisen unter anderem neue, verbesserte oder erweiterte Funktionalitäten sowie Bugfixes auf. In manchen Fällen beinhaltet eine neue Paketversion allerdings auch unterschiedliches Verhalten bei gleichbleibendem Code oder neue Abhängigkeiten zu anderen Paketen, der Programmiersprache selbst oder anderen Systemkomponenten, wie b, auf die aktuellen oder vergangenen Paketversionen zugreifen und diese für ihre Arbeit benutzen. Ein wichtiger Aspekt dabei ist die kontinuierliche Weiterentwicklung vieler Pakete. Neue Paketversionen weisen unter anderem neue, verbesserte oder erweiterte Funktionalitäten sowie Bugfixes auf. In manchen Fällen beinhaltet eine neue Paketversion allerdings auch unterschiedliches Verhalten bei gleichbleibendem Code oder neue Abhängigkeiten zu anderen Paketen, der Programmiersprache selbst oder anderen Systemkomponenten, wie b, spw., spw., dem zugrundeliegenden Betriebssystem. Solche Veränderungen erfordern zusätzliche Anpassungen, um die Funktionalität des bereits entwickelten Codes weiterhin zu gewährleisten. So muss der Code beispielsweise auf neue Verhaltensweisen der Pakete angepasst werden oder weitere Pakete, dem zugrundeliegenden Betriebssystem. Solche Veränderungen erfordern zusätzliche Anpassungen, um die Funktionalität des bereits entwickelten Codes weiterhin zu gewährleisten. So muss der Code beispielsweise auf neue Verhaltensweisen der Pakete angepasst werden oder weitere Pakete, müssen, müssen, installiert werden, um den Abhängigkeiten gerecht zu werden. Vor allem in Produktivsystemen, die nicht nur eine nahezu ständige Funktionalität garantieren müssten, sondern an denen oftmals eine Vielzahl von Entwicklern arbeiten, ist es wichtig, dass Updates der Paketlandschaft schnell und problemlos durchgeführt werden., installiert werden, um den Abhängigkeiten gerecht zu werden. Vor allem in Produktivsystemen, die nicht nur eine nahezu ständige Funktionalität garantieren müssten, sondern an denen oftmals eine Vielzahl von Entwicklern arbeiten, ist es wichtig, dass Updates der Paketlandschaft schnell und problemlos durchgeführt werden., , Im Idealfall arbeiten alle Entwickler in identischen Umgebungen, also mit den gleichen Paketen und Paketversionen. Arbeiten die Entwickler, jedoch, mit unterschiedlichen Paketversionen,, bei, denen es Änderungen von den Entwicklern genutzten Funktionalitäten gibt, entstehen möglicherweise, unterschiedliche, Skripte und Analysen, . Diese funktionieren dann nicht einheitlich bei allen Entwicklern, wodurch entweder Fehler verursacht oder unterschiedliche Ergebnisse geliefert werden., Zusätzlich zu der Gefahr, dass Skripte ein anderes Verhalten in den verschiedenen Umgebungen der Entwickler aufweisen, besteht die Gefahr, dass die Paketversionen der Entwickler von denen des Produktivsystems abweichen, in dem die Analysen gewinnbringend eingesetzt werden und somit nahezu ständig funktionieren müssen. Um Konflikte zwischen unterschiedlichen Paketversionen in der Entwicklung zu vermeiden, ,, versucht man mit einer guten Infrastruktur für ein reibungsloses Paketmanagement zu sorgen, welches gleiche Entwicklungsbedingungen und geregelte, und, synchrone Updates garantiert., Eine erste Maßnahme, um die Grundlage für ein gutes Paketmanagement zu schaffen, ist die Bereitstellung von Paketen in einem lokalen, unternehmens- oder teamweiten Repository. Das lokale Repository funktioniert für die Entwickler wie ein Online-Repository, wobei im lokalen Repository nur ausgewählte Pakete und Paketversionen zur Verfügung stehen. Somit haben alle Data, Scientists, Zugriff auf das gleiche zentrale Paketarchiv, während gleichzeitig sichergestellt werden kann, dass die Paketversionen im Repository weitestgehend stabil sind und alle Abhängigkeiten erfüllt sind. Somit wird vor allem garantiert, dass sich die entwickelten Algorithmen bzw. der Code unternehmensweit in den verschiedenen Entwicklungsumgebungen und im Produktivsystem gleich verhalten. Allerdings kann dabei nicht immer die Koexistenz von unterschiedlichen Versionen des gleichen Pakets gewährleistet werden, da somit wieder die Gefahr wie im Falle eines Online-, Repositories, besteht, also, dass verschiedene Entwickler auf unterschiedlichen Paketversionen entwickeln., Hierfür eignet sich der, RStudio, Package Manager. Der, RStudio, Package Manager agiert als Brücke, um verschiedene Paketquellen, wie z.B. Online Repository,, Local, Repository und u.a. externes Entwicklungs-Repository (, GitLab, ) miteinzubinden. Unternehmen mit restriktiven Corporate-, Governance, -Grundsätzen wollen lediglich eine abgesegnete Teilmenge der Pakete in ihrem lokalem Repository haben., , Um diesem Problem vorzubeugen, kann man auch das lokale Repository um unterschiedliche Paketversionen erweitern und die Einschränkung auf eine bestimmte Version innerhalb unterschiedlicher Projekte gewährleisten. Dafür, wird für jedes Projekt eine Projektumgebung definiert, , die einen bestimmten Teil der Pakete des lokalen, Repositories, enth, ält, und auf fixe Paketversionen beschränkt, ist, . Dies hat den Vorteil, dass in unterschiedlichen Projekten mit unterschiedlichen Paketen bzw. Paketversionen gearbeitet werden kann, während man innerhalb eines Projekts eine projektweit stabile und konfliktfreie Paketwelt bereitstellt. Für die Data, Scientists, bedeutet das entweder die Entwicklung auf einem zentralen Entwicklungssystem (bspw. einem, RStudio, -Server) oder auf ihrem lokalen System mit den für das Projekt definierten Paketen zu arbeiten (bspw. als R-Projekt oder, conda, , environment, , wahlweise innerhalb eines Docker Containers). Zusätzlich, wird ein Produktivsystem betrieben, , welches eine zu der Entwicklungsumgebung identische Paketlandschaft umfasst. In diesem Fall stellt das lokale Repository vor allem eine zusätzliche Sicherheitsebene dar, um nur Pakete zur Verfügung zu stellen, die sich über einen gewissen Zeitraum als stabil erwiesen haben und die möglicherweise bereits erste Bugfixes enthalten., , Ist es an der Zeit ein Update der Pakete durchzuführen, sollte dies nahezu zeitgleich auf den Entwicklungs- und Produktivumgebungen geschehen, um ein unterschiedliches Verhalten der Umgebungen auf einen möglichst kleinen Zeitraum zu beschränken., Es ist, besonders wichtig, dass das Produktivsystem ohne Unterbrechungen stabil läuft, . Daher e, mpfiehlt es sich ein Testsystem einzurichten, auf dem die Updates zuvor durchgeführt werden, um fehlende Paketabhängigkeiten oder Konflikte zwischen bestimmten Paketversionen zu prüfen. Hat man auf dem Testsystem einen stabilen Zustand erreicht, kann man zunächst die Entwicklungsumgebungen updaten, um gegebenenfalls die Algorithmen und Analysen auf die neuen Paketversionen anzupassen. Ein Update der Paketwelt auf dem Produktivsystem kann dann zeitgleich mit den bereits auf den Entwicklungsumgebungen getesteten Anpassungen der Analysen geschehen, um das Fehlerrisiko auf dem Produktivsystem so gering wie möglich zu halten. Um solche Updates regelmäßig schnell und problemlose durchzuführen, ist eine verlässliche Infrastruktur von großer Bedeutung. Dabei hängt der Aufbau einer solchen Infrastruktur von vielen Faktoren ab, wie zum Beispiel Anzahl der Projekte, Größe der Entwicklerteams oder Länge der Updatezyklen., , Ein gutes Paketmanagement in Produktivsystemen und eine vollkommen funktionsfähige Infrastruktur sind die Grundlage für eine komplikationsfreie Entwicklungsumgebung., Gern unterstützen und beraten wir Sie bei der Planung bzw.Implementierung einer IT-Infrastrukturin Ihrem Unternehmen. Erfahren Sie mehr über, !, ,  - Beitrag vom 21.11.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/package-management-einsatz-von-repositories-in-produktivsystemen;EODA;
14.11.2019;Filter, die Analystenherzen höher schlagen lassen;, ×,  - Beitrag vom 14.11.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/filter-die-analystenherzen-hoeher-schlagen-lassen;EODA;
23.10.2019;Kubernetes: Horizontale Skalierung von Data-Science-Anwendungen in der Cloud;, ×, Kubernetes:, Skalierung, Data-Science-Anwendungen, Cloud, Kubernetes, Job-Launcher, Fazit,  - Beitrag vom 23.10.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/horizontale-skalierung-von-data-science-anwendungen-in-der-cloud;EODA;
16.09.2019;R, Python und Julia in Data Science: Ein Vergleich;", ×, Data Science, „In welcher Programmiersprache soll entwickelt werden?“, R &amp; RStudio, Python &amp; Jupyter Notebook, barrierefreier Workflow, effizient,  - Beitrag vom 16.09.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/r-python-julia-in-data-science-ein-vergleich;EODA;
04.09.2019;Einfacher Datenzugang: Die Vorteile der einmaligen Datenbankverbindung mit ODBC und DBI ;, ×, Vorteile, Datenbankverbindung, Jeder Entwickler hat seine Lieblingstools und, Frameworks, mit denen er arbeitet, wenn er eine Verbindung zur Datenbank herstellt. Die Anzahl an verschiedenen Front-End und Back-End Kombinationen erhöhe, n die Komplexität der Analysen. Auch jedes Relational Database Management System, , (, RDBMS), das einen eigenen Treiber braucht, kann unter Umständen plattform- und sprachenabhängig, sein, ., Aus diesem Grund können viele Arten von Datenbank-Performance-Problemen entstehen., , Durch, die Bereitstellung eines Servers verschiebt sich der wiederkehrende clientseitige Konfi, g, urationsaufwand zu, einer e, inmalige, n, zentrale, n, Konfiguration von verschiedenen Datenbanktreibern, . So wird die Nähe zu den Daten geschaffen und schließlich ein nutzerfreundlicher Zugang ermöglicht., , Besonders wichtig ist, ein, optimaler, Datenz, ugang für die Arbeit von Data Scientists., Er ermöglicht ihnen einen schnellen und effizienten Zugriff auf die relevanten Daten., Die Verbindung, Die Verbindung, des, des, RBDMS, RBDMS, zur, zur, I, I, nteg, nteg, rated Development Environm, rated Development Environm, en, en, t (IDE, t (IDE, ), ), findet über ein, findet über ein, B, B, ack, ack, –, –, E, E, nd statt, nd statt, . Dieses, . Dieses, kann, kann, b, b, spw., spw., , , durch, durch, J, J, ava, ava, D, D, atabase, atabase, C, C, onnectivit, onnectivit, y, y, , , (, (, JDBC, JDBC, ), ), , , oder , oder , O, O, pen, pen, D, D, atabase, atabase, C, C, onnectivity, onnectivity, (ODBC), (ODBC), bereitgestellt werden., bereitgestellt werden., Beide, Beide, B, B, ack, ack, –, –, E, E, nds haben eine API (, nds haben eine API (, Application, Application, , , Programming, Programming, Interface), Interface), , die clientseitig die Kommunikation mit der Datenbank realisieren., , die clientseitig die Kommunikation mit der Datenbank realisieren., , , Beide Back-End-Systeme werden standardmäßig von vielen RDBMS-Anbietern bereitgestellt, jedoch gibt es einen zentralen Unterschied: Während das ODBC Back-End sprachenunabhängig ist, ist das JDBC von der Programmiersprache Java abhängig. Zwar spiegelt sich die Sprachenunabhängigkeit von ODBC in einer höheren Komplexität des Back-Ends wider, jedoch können zusätzliche Ebenen, wie z.B. die Kommunikation von JDBC zu MS SQL (linke Seite) mittels ODBC vermieden werden., Beide Back-End-Systeme werden standardmäßig von vielen RDBMS-Anbietern bereitgestellt, jedoch gibt es einen zentralen Unterschied: Während das ODBC Back-End sprachenunabhängig ist, ist das JDBC von der Programmiersprache Java abhängig. Zwar spiegelt sich die Sprachenunabhängigkeit von ODBC in einer höheren Komplexität des Back-Ends wider, jedoch können zusätzliche Ebenen, wie z.B. die Kommunikation von JDBC zu MS SQL (linke Seite) mittels ODBC vermieden werden., Schließlich lässt sich sagen, dass die Verwendung des ODBC Back-Ends, Schließlich lässt sich sagen, dass die Verwendung des ODBC Back-Ends, vorteilhaft, vorteilhaft, ist, ist, , da dieses plattform- und sprachenunabhängig ist., , da dieses plattform- und sprachenunabhängig ist., Als, F, ront, –, E, nd, ist es empfehlenswert interlingual das, D, ataBase, Interface (DBI), zu verwenden. Dieses Interface, definiert, ein Set an Klassen und Methoden, die ähnlich in, R’s, DBI,, Perl’s, ?, DBI, und, , Python’s, ?, DB-API, , implentiert, sind, ., D, ieses schleust uniforme Kommandos zum, ODBC, , B, ack-, E, nd, welches die Befehle in die, r, ichtige, Datenbankmanagementsystem, –, Logik übersetzt. Dieser Ansatz erlaubt es, eine Verbindung mit einer Datenbank (bspw., SQL Server, ,?, Oracle, ,?, MySQL, ,?, PostgreSQL, ,?, SQLite etc.), , effizient und sehr leicht, aufzubauen,, sofern, die grundlegenden ODBC, –, Treiber installiert sind., , , Zusätzlich bietet es den Vorteil, jede Datenbank mit den gleichen Funktionen und Methoden anzusprechen., , Die Installation und Konfiguration der ODBC ist, dabei die Arbeit, die den größten Aufwand erfordert, ., ,  - Beitrag vom 04.09.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/einfacher-datenzugang-die-vorteile-der-einmaligen-datenbankverbindung-mit-odbc-und-dbi;EODA;
27.08.2019;Data science courses with R in Frankfurt!;, ×,  - Beitrag vom 27.08.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-courses-with-r-in-frankfurt;EODA;
27.08.2019;Anomalieerkennung in Zeitreihen: Welcher Algorithmus ist der Richtige?;, ×, Algorithmus,  - Beitrag vom 27.08.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/anomalieerkennung-in-zeitreihen-welcher-algorithmus-ist-der-richtige;EODA;
22.08.2019;Ausreißer in der Datenflut: Mit der Anomalieerkennung Maschinenausfälle vermeiden;, ×, Anomalieerkennung,  - Beitrag vom 22.08.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/mit-der-anomalieerkennung-maschinenausfaelle-vermeiden;EODA;
14.08.2019;Authentifizierung und Autorisierung: Datensicherheit für Data-Science-Umgebungen;, ×, Eine wesentliche Frage f, Eine wesentliche Frage f, ü, ü, r den Ausbau und die nachhaltige Nutzung von IT-Systemen ist die zentrale Steuerung und Verwaltung von Benutzern und Rechten., r den Ausbau und die nachhaltige Nutzung von IT-Systemen ist die zentrale Steuerung und Verwaltung von Benutzern und Rechten., Betrachtet man, Betrachtet man, d, d, ie implementierten Systeme, lassen sich zwei Fragestellungen ableiten:, ie implementierten Systeme, lassen sich zwei Fragestellungen ableiten:, Wer meldet sich am System an (Authentifizierung) und welche Rechte besitzt diese Person auf dem genutzten System (Autorisierung, Wer meldet sich am System an (Authentifizierung) und welche Rechte besitzt diese Person auf dem genutzten System (Autorisierung, ), ), ?, ?,  Bei der Implementierung einer optimalen Analyseumgebung sind die Authentifizierung und Autorisierung wichtige Komponenten für ein einwandfreies Betriebssystem.,  Bei der Implementierung einer optimalen Analyseumgebung sind die Authentifizierung und Autorisierung wichtige Komponenten für ein einwandfreies Betriebssystem., Im Hinblick auf die, Im Hinblick auf die, Sensibilit, Sensibilit, ä, ä, t der Daten, sind besondere Anforderungen notwendig,, t der Daten, sind besondere Anforderungen notwendig,, um den Datensch, um den Datensch, u, u, tz jederzeit zu wahren und, tz jederzeit zu wahren und, die, die, jeweils relevant, jeweils relevant, en Informationen, en Informationen, den Nutzern, den Nutzern, bereit zu stellen, bereit zu stellen, ., ., Die Authentifizierung und Autorisierung, Die Authentifizierung und Autorisierung, sind die, sind die, notwendige, technische Voraussetzung f, notwendige, technische Voraussetzung f, ü, ü, r den fl, r den fl, ä, ä, chen, chen, deckenden Roll-out, deckenden Roll-out, von Data-Science-L, von Data-Science-L, ö, ö, sungen., sungen., , Authentifizierung, Wer kennt es nicht: Nur mit einer Bankkarte und der dazugeh, ö, rigen PIN, l, ä, sst sich an einem Bankautomaten, Bargeld, , abheben. Diese voneinander, unab, h, ä, ngigen Komponenten, (Faktoren) werden f, ü, r den Identit, ä, tsnachweis eines Nu, tzers abgefragt, um, sicherheitskritische Anwendungsbereiche, und Systeme, sc, h, ü, tzen zu k, ö, nnen., Authentifizierungssysteme k, ö, nnen einfache Nutzer- und Kennwort-Abfragen sein, werden aber bei sicherheitskritischen Systemen gerne mit weiteren Abfragen als Zwei-Faktor-Authentifizierung kombiniert., , Nachdem ein Nutzer sich mit der Eingabe seines Benutzernamens und Passwort, s, authentisiert hat, folgt die Authentifizierung. Diese pr, ü, ft und best, ä, tigt die, Identit, ä, t des Nutzers, ,, gleicht die eingegebenen Daten mit den entsprechenden gespeicherten ab, und best, ä, tigt, en, tweder, die Korrektheit der Anmeldedaten, , oder lehnt diese ab, und, verweigert, schlie, ß, lich, den Zugang, , zur Applikation, ., , Information, Die Authentisierung ist der erste Schritt zur Pr, Die Authentisierung ist der erste Schritt zur Pr, ü, ü, fung der Identit, fung der Identit, ä, ä, t und stellt somit, t und stellt somit, den, den, aktiv, aktiv, zu erbringe, zu erbringe, nden, nden, Nachweis einer Person dar., Nachweis einer Person dar., D, D, ies, ies, bedeutet, dass die Person, bedeutet, dass die Person, diejenige ist, die sie vorgibt zu sein, diejenige ist, die sie vorgibt zu sein, ., ., , , So verf, So verf, ü, ü, gt sie beispielsweise, gt sie beispielsweise, ü, ü, ber, ber, geheime Informationen, die nur ihr bekannt sind (, geheime Informationen, die nur ihr bekannt sind (, z.B., z.B., Passwort) oder besitzt einen Identifizierungsgegenstand (, Passwort) oder besitzt einen Identifizierungsgegenstand (, z.B., z.B., Personalausweis), Personalausweis), ., ., , Autorisierung , Nach einer erfolgreichen Authentifizierung erh, Nach einer erfolgreichen Authentifizierung erh, ä, ä, lt der Nutzer Zugriffsrechte auf die, lt der Nutzer Zugriffsrechte auf die, Applikation., Applikation., An dieser Stelle, An dieser Stelle, kommt die Autorisierung zu tragen., kommt die Autorisierung zu tragen., Die Autorisierung, Die Autorisierung, ü, ü, berwindet Mechanismen von Sicherungen gegen Unbefugte., berwindet Mechanismen von Sicherungen gegen Unbefugte., Um nicht f, Um nicht f, ü, ü, r jeden einzelnen Nutzer individuelle Zugriffsrechte festlegen zu m, r jeden einzelnen Nutzer individuelle Zugriffsrechte festlegen zu m, ü, ü, ssen, werden Rollen zugeordnet, ssen, werden Rollen zugeordnet, , die an beliebig viele Benutzer vergeben werden k, , die an beliebig viele Benutzer vergeben werden k, ö, ö, nnen, nnen, . Benutzer, die einer bestimmten Rolle zugeteilt sind, sind dann autorisiert, spezifische Zugriffe durchzuf, . Benutzer, die einer bestimmten Rolle zugeteilt sind, sind dann autorisiert, spezifische Zugriffe durchzuf, ü, ü, hren., hren., H, H, ä, ä, ufige Beispiele f, ufige Beispiele f, ü, ü, r die Nutzung von Rollen ist die Aufteilung zwischen normalen Nutzern des Systems und Admins, aber auch die Steuerung von Zugriffen auf bestimmte Datent, r die Nutzung von Rollen ist die Aufteilung zwischen normalen Nutzern des Systems und Admins, aber auch die Steuerung von Zugriffen auf bestimmte Datent, ö, ö, pfe k, pfe k, ö, ö, nnen auf diesem Weg reglementiert werden., nnen auf diesem Weg reglementiert werden., , Geregelte Benutzerrechte durch ein zweischichtiges Konzept, Geregelte Benutzerrechte durch ein zweischichtiges Konzept, Geregelte Benutzerrechte durch ein zweischichtiges Konzept, , Die Authentifizierung und Autorisierung finden jeweils, durch die Applikation statt, , welche diese Aufgabe in Zusammenarbeit mit einem zentralen Identit, ä, tsmanagements als externen Dienst l, ö, sen kann, ., In diesem, zweischichtige, n, Konzept, wird, erst die Identit, ä, t und, anschlie, ß, end, die Berechtigungen des Endnutzers verifizier, t, ., Durch, dieses Vorgehen wird, gew, ä, hrleistet, dass nur Nutzer Zugriff auf das System haben, die einer bestimmten Gruppe i, m, Verzeichnisdienst, (bspw., ActiveDirectory, ), zugeh, ö, rig sind., Auf den Systemen, lassen sich, durch, die Autorisierung neben d, en, verf, ü, gbaren Ressourcen, , auch Befehle des Nutzers, steuern, ., , Beispiel, E, E, ine Person aus Deutschland, die in der Sales, ine Person aus Deutschland, die in der Sales, –, –, Abteilung arbeitet, Abteilung arbeitet, ,, ,, ist ausschlie, ist ausschlie, ß, ß, lich berechtigt, lich berechtigt, Kundend, Kundend, a, a, ten, ten, aus Deutschland zu sehen. De, aus Deutschland zu sehen. De, n, n, Zugriff auf andere, Zugriff auf andere, Kundendaten, Kundendaten, werden der Person verweigert, da sie nicht autorisiert ist die, werden der Person verweigert, da sie nicht autorisiert ist die, se, se, Daten einzusehen. Komplement, Daten einzusehen. Komplement, ä, ä, r hierzu werden die Zugriffe f, r hierzu werden die Zugriffe f, ü, ü, r andere L, r andere L, ä, ä, nder definiert., nder definiert., , , Der Leiter des Vertriebs f, Der Leiter des Vertriebs f, ü, ü, r Europ, r Europ, a, a, hingegen erh, hingegen erh, ä, ä, lt die Rollen f, lt die Rollen f, ü, ü, r alle europ, r alle europ, ä, ä, ischen L, ischen L, ä, ä, nder und damit Zugriff auf deutlich mehr Daten., nder und damit Zugriff auf deutlich mehr Daten., , Eine wiederkehrende Herausforderung ist die trennscharfe Definition von Rollen. Sind wir im Beispiel noch auf die einfache Vergabe von Rollen f, ü, r jedes Land beschr, ä, nkt, ,, bewegen wir uns in der Praxis h, ä, ufig auf deutlich mehr Dimensionen. Teilt man die Daten im Beispiel auf, Adresse, Umsatzzahlen und den Zugriff auf E-Mails des Kunden auf, so ergibt sich schnell ein, wesentlich, komplexeres Konzept., , Gerade bei Abteilungs- und damit, r, ollen, ü, bergreifenden Projektteams gibt es hier besondere Herausforderungen, die sich durch den gro, ß, en Spielraum mit Gruppen inActiveDirectoriesabbilden lassen. So k, ö, nnen Fachexperten aus verschiedenen Abteilungen ein Projektteam bilden, welches losgel, ö, st von bestehenden Abteilungen nebenher existieren kann, ohne die bisherigen Berechtigungen zu verlieren., , Berechtigungskonzept mittels technischer Nutzer, Berechtigungskonzept mittels technischer Nutzer, Berechtigungskonzept mittels technischer Nutzer, , Ein weiteres, , h, ä, ufig genutztes, Prinzip, eines Berechtigungskonzeptes, ist die Verwendung von technischen Nutzern, . Diese finden in der Regel Verwendung, falls keine Login, –, Maske auf App, –, Ebene gew, ü, nscht oder realisierbar ist, und lediglich die Rechte der Applikation selbst gesteuert werden k, ö, nnen, ., , In komplexeren IT-Landschaften werden technische Nutzer h, ä, ufig zur Anbindung bestimmter Dienste verwendet obwohl der personalisierte Nutzer bekannt ist. In diesem Fall k, ö, nnen Informationen, ü, ber den angemeldeten Benutzer durch die Applikation an angebundene Systeme weitergereicht werden. Beispielsweise als Bedingungen innerhalb von Abfragen an Datenbanken., , Die folgende, Infografik, illustriert, basierend auf dem, v, orangegangenen Beispiel, den Einsatz eines technischen Users. In diesem Beispiel authentifiziert sich der Nutzer gegen eine Applikation, welche zun, ä, chst bestimmt ob, ü, berhaupt Zugriff auf das System besteht., Eine Möglichkeit für eine Applikation kann einRStudio-Server sein, der eine korrekte Authentifizierung voraussetzt., , Es l, ä, sst sich erkennen, dass der in orange a, bgebildete Nutzer sich nicht erfolgreich authentifiziert hat, ,, wodurch ihm, der, Zugang, zur Anwendung, verweigert wird., Die App selbst baut jedoch eine, Datenbankanbindung mit einem technischen User auf. Um die korrekte Autorisierung sicherzustellen wird s, ä, mtlichen SQL-Abfragen der User als Parameter mitgegeben, wodurch der Zugriff weiterhin durch entsprechende Strukturen innerhalb der Datenbank gesteuert werden kann., , , , Die Authentifizierung und Autorisierung sind, Die Authentifizierung und Autorisierung sind, wichtige, wichtige, Komponente, Komponente, n einer, n einer, IT-Infrastruktur für datengestützte Unternehmen, IT-Infrastruktur für datengestützte Unternehmen, . Im Rahmen unseres, . Im Rahmen unseres, eoda, eoda, |, |, analytic, analytic, , , infrastrucure, infrastrucure, , , consulting, consulting, unterstützen wir Sie beim Aufbau Ihrer produktiven Data-Science, unterstützen wir Sie beim Aufbau Ihrer produktiven Data-Science, -Umgebung!, -Umgebung!, Die Benutzerverwaltung ist auch eines der zentralen Features unserer eigenen Analytikplattform YUNA. Erfahren Sie mehr zu unserer Lösung.,  - Beitrag vom 14.08.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/authentifizierung-und-autorisierung-datensicherheit-fuer-data-science-umgebungen;EODA;
25.07.2019;Ei Gude! - Data Science Kurse mit R in Frankfurt;, ×, 12. – 13. November 2019 | Einführung in R, 14. – 15. November 2019 | Machine Learning mit R,  - Beitrag vom 25.07.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/ei-gude-data-science-kurse-mit-r-in-frankfurt;EODA;
24.07.2019;;, ×, Data-Science-Event 2019,  - Beitrag vom 24.07.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/ready-for-production-rueckblick-auf-das-data-science-event-2019-mit-rstudio-und-eoda;EODA;
18.11.2018;Entwicklungsumgebungen: Welche ist die richtige für R und Python?;, ×,  Starten Sie jetzt mit R und Python durch,  - Beitrag vom 18.11.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/entwicklungsumgebungen-welche-ist-die-richtige-fuer-r-und-python;EODA;
26.10.2018;Feature-Engineering Preisindizes: Kaufverhalten verstehen;, ×, Feature Engineering, Mit der Clusteranalyse zu Mehrwerten auf Datenbasis,  - Beitrag vom 26.10.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/feature-engineering-preisindizes-kaufverhalten-verstehen;EODA;
18.09.2018;Das Beste vereint? Wie die Programmiersprache Julia den Markt erobern will;, ×, Training: Data Science mit Julia,  - Beitrag vom 18.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/das-beste-vereint-wie-die-programmiersprache-julia-den-markt-erobern-will;EODA;
08.05.2018;;, ×,  - Beitrag vom 08.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/b-wie-bias;EODA;
02.05.2018;Flexdashboard: Einfache HTML-Dashboards mit R;, ×, flexdashboard::flex_dashboard,  Erschließen Sie Ihr Datenpotenzial,  - Beitrag vom 02.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/flexdashboard-html-dashboards-mit-r;EODA;
25.01.2018;Das erfolgreiche Data-Science-Projekt: Wie funktioniert es?;, ×, Whitepaper,  Erschließen Sie Ihr Datenpotenzial,  - Beitrag vom 25.01.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-projekt-wie-funktioniert-es;EODA;
04.08.2017;Öffentlich verfügbare Datensätze: Mit „Titanic“ auf der Suche nach der Wahrheit – musste Jack wirklich sterben?;, ×, verfügbare Datensätze, Data Science Trainings in R,  - Beitrag vom 04.08.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/oeffentlich-verfuegbare-datensaetze-titanic;EODA;
11.12.2013;Professioneller R Code – einfach eigene Pakete erstellen und dokumentieren;, ×,  Erschließen Sie Ihr Datenpotenzial,  - Beitrag vom 11.12.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/r-code-eigene-pakete-erstellen-dokumentieren;EODA;
10.10.2013;Veracity – Sinnhaftigkeit und Vertrauenswürdigkeit von Big Data als Kernherausforderung im Informationszeitalter;, ×,  Erschließen Sie Ihr Datenpotenzial,  - Beitrag vom 10.10.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/veracity-big-data-herausforderung;EODA;
15.09.2013;Text Mining mit R – „unstrukturierte“ Daten analysieren;, ×, Werden Sie zum ExpeRten!,  - Beitrag vom 15.09.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/text-mining-mit-r-unstrukturierte-daten-analysieren;EODA;
14.08.2013;Zeitreihenanalyse mit R – Entscheidungsgrundlage und Potentialfaktor;, ×, Zeitreihenanalyse, Schöpfen Sie ihr digitales Potenzial voll aus!,  - Beitrag vom 14.08.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/zeitreihenanalyse-r-entscheidungsgrundlage-potentialfaktor;EODA;
08.05.2012;Clusteranalyse in der Kundensegmentierung;, ×, Kundensegmentierung, Mit der Clusteranalyse zu Mehrwerten auf Datenbasis,  - Beitrag vom 08.05.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/clusteranalyse-in-der-kundensegmentierung;EODA;
10.05.2019;data science news monthly | April 2019;, ×,  - Beitrag vom 10.05.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-april-2019;EODA;
02.05.2019;Ready for production: Das Data-Science-Event 2019 mit eoda und RStudio;, ×,  - Beitrag vom 02.05.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/ready-for-production-das-data-science-event-2019-mit-eoda-und-rstudio;EODA;
23.04.2019;Client-Server-Architekturen: Performance und Agilität für Data Science;, ×,  - Beitrag vom 23.04.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/client-server-architekturen-performance-und-agilitaet-fuer-data-science;EODA;
02.04.2019;data science news monthly | März 2019;, ×,  - Beitrag vom 02.04.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-monthly-maerz-2019;EODA;
19.03.2019;Data Science und IT – eine Frage der richtigen Infrastruktur;, ×,  - Beitrag vom 19.03.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-und-it-eine-frage-der-richtigen-infrastruktur;EODA;
14.03.2019;Reinforcement Learning: Wie man einer KI das Spielen beibringt;, ×,  - Beitrag vom 14.03.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/reinforcement-learning-wie-man-einer-ki-das-spielen-beibringt;EODA;
20.02.2019;Mit Data-Science-Hackathons schnell zu ersten Ergebnissen;, ×,  - Beitrag vom 20.02.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/mit-data-science-hackathons-schnell-zu-ersten-ergebnissen;EODA;
19.02.2019;data science news monthly | Februar 2019;, ×,  - Beitrag vom 19.02.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-monthly-februar-2019;EODA;
23.01.2019;Data Science Trends 2019;, ×, Kein Jahresanfang ohne Vorhersagen und Trend-Berichte: Auch wir bei eoda haben den Jahreswechsel zum Anlass genommen, Kein Jahresanfang ohne Vorhersagen und Trend-Berichte: Auch wir bei eoda haben den Jahreswechsel zum Anlass genommen, und, und, ge, ge, schau, schau, t, t, , , welche Trends wir in unseren Projekten wahrgenommen haben., welche Trends wir in unseren Projekten wahrgenommen haben., , , , , , , , , , , , , , Blog,  - Beitrag vom 23.01.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-trends-2019;EODA;
22.01.2019;data science news monthly | Januar 2019;, ×, Hindernisse und Herausforderungen, Transparenz bei künstlicher Intelligenz, YouTube-Algorithmus, „AlphaStar“, kann Deutschland da überhaupt noch mithalten?, Dienste der mächtigen Unternehmen auszukommen, Data Scientists sind die gefragten Schatzsucher in Big Data, Hannover Messe,  - Beitrag vom 22.01.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-monthly-januar-2019;EODA;
17.01.2019;Industrie 4.0-Konferenz 2019;, ×,  - Beitrag vom 17.01.2019, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/industrie-4-0-konferenz-2019;EODA;
28.12.2018;data science news monthly | Dezember 2018;, ×,  - Beitrag vom 28.12.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-monthly-3;EODA;
19.12.2018;Data-Science-Konferenzen 2019;, ×,  - Beitrag vom 19.12.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-konferenzen-2019;EODA;
11.12.2018;Ist der Weihnachtsmann berechenbar?;, ×,  - Beitrag vom 11.12.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/ist-der-weihnachtsmann-berechenbar;EODA;
04.12.2018;data science news monthly | November 2018;, ×,  - Beitrag vom 04.12.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-monthly-2;EODA;
21.11.2018;E wie Ensemble Modeling;, ×,  - Beitrag vom 21.11.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/e-wie-ensemble-modeling;EODA;
09.11.2018;Versionierung in Data Science;, ×,  - Beitrag vom 09.11.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/versionierung-in-data-science;EODA;
30.10.2018;AI-Safari: In der europäischen Metropole der Künstlichen Intelligenz;, ×, , Google bietet das mit , Google bietet das mit , A, A, bstand größte Zentrum. Die Organisation der Start, bstand größte Zentrum. Die Organisation der Start, -U, -U, ps erfolgt, ps erfolgt,  bei ,  bei , G, G, oogle, oogle, auf , auf , verschiedenen Level, verschiedenen Level, s, s, . In der ersten Stufe reicht ein relativ einfaches Bewerbungsverfahren, um d, . In der ersten Stufe reicht ein relativ einfaches Bewerbungsverfahren, um d, en, en,  Service nutzen zu können. In den weiteren Stufen erfolgt ein ,  Service nutzen zu können. In den weiteren Stufen erfolgt ein , detaillierter, detaillierter,  Auswahlprozess. Auffällig war, dass die Unternehmen in der Eingangsstufe noch dicht gedrängt saßen, während ,  Auswahlprozess. Auffällig war, dass die Unternehmen in der Eingangsstufe noch dicht gedrängt saßen, während , die höheren Entwicklungsstufen , die höheren Entwicklungsstufen , deutlich luftiger besetzt waren., deutlich luftiger besetzt waren., Allen Hubs war gemeinsam, dass die , Allen Hubs war gemeinsam, dass die , AI , AI , Startups Cloudlösungen , Startups Cloudlösungen , entwickelt, entwickelt,  haben,  haben, . , . , Künstliche Intelligenz , Künstliche Intelligenz , ist , ist , somit , somit , ein weiterer Push, ein weiterer Push, -F, -F, aktor für die Cloud. , aktor für die Cloud. , Die Schlussfolgerung, Die Schlussfolgerung, , dass , , dass , AI zwingend eine Cloud voraussetzt wäre, AI zwingend eine Cloud voraussetzt wäre,  jedoch,  jedoch,  falsch. ,  falsch. , Es gibt viele Szenarien, in den, Es gibt viele Szenarien, in den, lokal installierte , lokal installierte , AI, AI, –, –, Lösungen Sinn machen und funktionieren. Nur findet man diese nicht in der Londoner , Lösungen Sinn machen und funktionieren. Nur findet man diese nicht in der Londoner , AI, AI, –, –, S, S, z, z, ene., ene.,  - Beitrag vom 30.10.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/ai-safari-in-der-europaeischen-metropole-der-kuenstlichen-intelligenz;EODA;
29.10.2018;data science news monthly | Oktober 2018;, ×,  - Beitrag vom 29.10.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-monthly;EODA;
24.10.2018;Case Study: Predictive Maintenance mit Deep-Learning-Algorithmen in der Industrie 4.0;, ×,  - Beitrag vom 24.10.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-predictive-maintenance-mit-deep-learning-algorithmen-in-der-industrie-4-0;EODA;
12.10.2018;Datenqualitätsprobleme lösen: Der richtige Umgang mit Betriebsstunden in der Industrie;, ×,  - Beitrag vom 12.10.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/datenqualitaetsprobleme-loesen-der-richtige-umgang-mit-betriebsstunden-in-der-industrie;EODA;
02.10.2018;eoda auf der data2day 2018;, ×,  - Beitrag vom 02.10.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-data2day-2018;EODA;
22.09.2018;data science news weekly #34;, ×, Im Zuge der Digitalisierung bestimmt das Thema Data Science immer mehr die Medienlandschaft und den gesellschaftlichen Diskurs. Technologische Innovationen, spannende Anwendungsfälle oder kontroverse Diskussionen: Wir behalten für Sie den Überblick und sammeln,  nützliche, interessante und hilfreiche Links rund um das Thema Data Science.,  - Beitrag vom 22.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-34;EODA;
21.09.2018;data science news weekly #33;, ×,  - Beitrag vom 21.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-33;EODA;
14.09.2018;data science news weekly #32;, ×,  - Beitrag vom 14.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-32;EODA;
11.09.2018;Augmented Intelligence: Menschliche Kognition trifft auf maschinelles Lernen;, ×,  - Beitrag vom 11.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/augmented-intelligence-menschliche-kognition-trifft-auf-maschinelles-lernen;EODA;
07.09.2018;data science news weekly #31;, ×,  - Beitrag vom 07.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-31;EODA;
05.09.2018;Fusion of the Industries: Ein Rückblick auf das Collabothon in Berlin;, ×,  - Beitrag vom 05.09.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/fusion-of-the-industries-ein-rueckblick-auf-das-collabothon-in-berlin;EODA;
31.08.2018;data science news weekly #30;, ×,  - Beitrag vom 31.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-30;EODA;
27.08.2018;Happy Birthday R;, ×,  - Beitrag vom 27.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/happy-birthday-r;EODA;
24.08.2018;data science news weekly #29;, ×,  - Beitrag vom 24.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-29;EODA;
24.08.2018;data science news weekly #28;, ×,  - Beitrag vom 24.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-28;EODA;
23.08.2018;Liebe Data Scientists, macht eure Arbeit noch wertvoller;, ×,  - Beitrag vom 23.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/liebe-data-scientists-macht-eure-arbeit-noch-wertvoller;EODA;
15.08.2018;Der nächste Zug ist entscheidend: Markow-Ketten als Prognosewerkzeug im schwierigen Terrain;, ×,  - Beitrag vom 15.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/der-naechste-zug-ist-entscheidend-markow-ketten-als-prognosewerkzeug-im-schwierigen-terrain;EODA;
13.08.2018;Der Point of Sale als Point of Information: Data Science im Einzelhandel;, ×,  - Beitrag vom 13.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/der-point-of-sale-als-point-of-information-data-science-im-einzelhandel;EODA;
10.08.2018;data science news weekly #27;, ×,  - Beitrag vom 10.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-27;EODA;
09.08.2018;D wie Deep Learning;, ×,  - Beitrag vom 09.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/d-wie-deep-learning;EODA;
03.08.2018;data science news weekly #26;, ×,  - Beitrag vom 03.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-26;EODA;
02.08.2018;Analytik im Unternehmen: Mit dem Data Science Canvas den richtigen Anwendungsfall finden;, ×,  - Beitrag vom 02.08.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/analytik-im-unternehmen-mit-dem-data-science-canvas-den-richtigen-anwendungsfall-finden;EODA;
31.07.2018;AI made in Germany: Der Masterplan für die digitale Zukunft?!;, ×,  - Beitrag vom 31.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/ai-made-in-germany-der-masterplan-fuer-die-digitale-zukunft;EODA;
27.07.2018;data science news weekly #25;, ×,  - Beitrag vom 27.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-25;EODA;
26.07.2018;Philipp Schmagold: „Eine finanzielle Förderung für die erste Beratungsleistung sollte sich kein KMU entgehen lassen.“;, ×,  - Beitrag vom 26.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/philipp-schmagold-eine-finanzielle-foerderung-fuer-die-erste-beratungsleistung-sollte-sich-kein-kmu-entgehen-lassen;EODA;
20.07.2018;data science news weekly #24;, ×,  - Beitrag vom 20.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-24;EODA;
19.07.2018;Trainings und Talks in Stuttgart: Sparen Sie 10% mit unserem Summer Special;, ×,  - Beitrag vom 19.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/trainings-und-talks-in-stuttgart-sparen-sie-10-mit-unserem-summer-special;EODA;
18.07.2018;Data Science in KMU: So gelingt der richtige Einstieg;, ×,  - Beitrag vom 18.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-in-kmu-so-gelingt-der-richtige-einstieg;EODA;
13.07.2018;data science news weekly #23;, ×,  - Beitrag vom 13.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-23-2;EODA;
12.07.2018;Digitale Transformation? Na logististisch!;, ×,  - Beitrag vom 12.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/digitale-transformation-na-logististisch;EODA;
10.07.2018;R goes Down Under: Ein Ausblick auf die useR! 2018 in Brisbane;, ×,  - Beitrag vom 10.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/r-goes-down-under-ein-ausblick-auf-die-user-2018-in-brisbane;EODA;
06.07.2018;data science news weekly #22;, ×,  - Beitrag vom 06.07.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-22;EODA;
29.06.2018;data science news weekly #21;, ×,  - Beitrag vom 29.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-21-2;EODA;
26.06.2018;C wie Clusteranalyse;, ×,  - Beitrag vom 26.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/c-wie-clusteranalyse;EODA;
22.06.2018;data science news weekly #20;, ×,  - Beitrag vom 22.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-20;EODA;
21.06.2018;Der digitale Zwilling: Möglichmacher der digitalen Transformation;, ×,  - Beitrag vom 21.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/der-digitale-zwilling-moeglichmacher-der-digitalen-transformation;EODA;
15.06.2018;data science news weekly #19;, ×,  - Beitrag vom 15.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-19;EODA;
12.06.2018;Liebe Data Scientists, macht euch die Arbeit leichter;, ×, ,  - Beitrag vom 12.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/liebe-data-scientists-macht-euch-die-arbeit-leichter;EODA;
08.06.2018;data science news weekly #18;, ×,  - Beitrag vom 08.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-18;EODA;
01.06.2018;»Die Frage lautet: Wie können Datenanalysen in eine professionelle IT-Umgebung eingebettet werden?«;, ×, Philipp Tschachtschal, Philipp Tschachtschal, arbeitet als Solution Architect bei der eoda GmbH. Dort berät er Unternehmen jeder Größe bei Fragen zur passenden IT-Infrastruktur im Data-Science-Kontext und sorgt so für eine reibungslose und nachhaltige Implementierung der Datenanalysen.,  - Beitrag vom 01.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-frage-lautet-wie-koennen-datenanalysen-in-eine-professionelle-it-umgebung-eingebettet-werden-2;EODA;
01.06.2018;data science news weekly #17;, ×,  - Beitrag vom 01.06.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-17;EODA;
25.05.2018;data science news weekly #16;, ×,  - Beitrag vom 25.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-16;EODA;
24.05.2018;It’s (almost) all about the Data: Stolpersteine von Predictive Maintenance;, ×,  - Beitrag vom 24.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/its-almost-all-about-the-data-stolpersteine-von-predictive-maintenance;EODA;
18.05.2018;data science news weekly #15;, ×,  - Beitrag vom 18.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-15;EODA;
11.05.2018;data science news weekly #14;, ×,  - Beitrag vom 11.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-14;EODA;
04.05.2018;data science news weekly #13;, ×,  - Beitrag vom 04.05.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-weekly-13;EODA;
27.04.2018;data science news weekly #12;, ×,  - Beitrag vom 27.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly-12;EODA;
24.04.2018;Risiken erkennen, Chancen nutzen: Data Science in der Versicherungsbranche;, ×,  - Beitrag vom 24.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/risiken-erkennen-chancen-nutzen-data-science-in-der-versicherungsbranche;EODA;
20.04.2018;data science news weekly #11;, ×,  - Beitrag vom 20.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-news-weekly;EODA;
17.04.2018;Mit Predictive Modelling und Kostenanalyse zur optimierten LKW-Flotte;, ×,  - Beitrag vom 17.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/mit-predictive-modelling-und-kostenanalyse-zur-optimierten-lkw-flotte;EODA;
13.04.2018;data science news weekly #10;, ×,  - Beitrag vom 13.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-10;EODA;
10.04.2018;Von der Ziel- bis zur Produktivsetzung: Ein Data-Science-Projekt Schritt für Schritt (Teil 2);, ×,  - Beitrag vom 10.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/von-der-ziel-bis-zur-produktivsetzung-ein-data-science-projekt-schritt-fuer-schritt-teil-2;EODA;
06.04.2018;data science news weekly #9;, ×,  - Beitrag vom 06.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-9;EODA;
05.04.2018;Von der Ziel- bis zur Produktivsetzung: Ein Data-Science-Projekt Schritt für Schritt (Teil 1);, ×,  - Beitrag vom 05.04.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/von-der-ziel-bis-zur-produktivsetzung-ein-data-science-projekt-schritt-fuer-schritt;EODA;
30.03.2018;data science news weekly #8;, ×,  - Beitrag vom 30.03.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-8;EODA;
23.03.2018;data science news weekly #7;, ×,  - Beitrag vom 23.03.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-data-science-week-7;EODA;
20.03.2018;A wie Algorithmus;, ×,  - Beitrag vom 20.03.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/a-wie-algorithmus;EODA;
16.03.2018;data science news weekly #6;, ×,  - Beitrag vom 16.03.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-6;EODA;
09.03.2018;data science news weekly #5;, ×,  - Beitrag vom 09.03.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-5-2;EODA;
02.03.2018;data science news weekly #4;, ×,  - Beitrag vom 02.03.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-4-2;EODA;
27.02.2018;Der Data Engineer als Wegbereiter erfolgreicher Data-Science-Projekte;, ×,  - Beitrag vom 27.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/der-data-engineer-als-wegbereiter-erfolgreicher-data-science-projekte;EODA;
23.02.2018;data science news weekly #3;, ×,  - Beitrag vom 23.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-3-2;EODA;
20.02.2018;Nachvollziehbar erfolgreich: Wieso Data Science so stark auf Open Source setzt;, ×,  - Beitrag vom 20.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/nachvollziehbar-erfolgreich-wieso-data-science-so-stark-auf-open-source-setzt;EODA;
16.02.2018;data science news weekly #2;, ×,  - Beitrag vom 16.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-2-2;EODA;
13.02.2018;Das erfolgreiche Data-Science-Projekt: Das Team und seine Kompetenzen;, ×,  - Beitrag vom 13.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/das-erfolgreiche-data-science-projekt-das-team-und-seine-kompetenzen;EODA;
09.02.2018;data science news weekly #1;, ×,  - Beitrag vom 09.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/lets-call-it-a-data-science-week-1-2;EODA;
01.02.2018;Quo vadis Finance? Wie die Finanzbranche mit Data Science von der Digitalisierung profitieren kann;, ×,  - Beitrag vom 01.02.2018, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/quo-vadis-finance-wie-die-finanzbranche-mit-data-science-von-der-digitalisierung-profitieren-kann;EODA;
15.12.2017;Data Wonderland: Weihnachtssongs aus der Sicht eines Data Scientists;, ×,  - Beitrag vom 15.12.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-wonderland-weihnachtssongs-aus-der-sicht-eines-data-scientists;EODA;
08.12.2017;»Eine durchdachte Analysestrategie ist wichtiger als die Frage: R oder Python.«;, ×, Martin Guist, Martin Guist, ist studierter Diplom Ingenieur und bei eoda in der Softwareentwicklung tätig. An seiner täglichen Arbeit reizt ihn nicht nur das Interdisziplinäre, sondern besonders die Möglichkeit, mit wenigen Mitteln etwas Neues zu kreieren. Martin begreift sich also als Erfinder und das passt gut: Aktuell lebt er sich in der weiteren Produktentwicklung des data science environments aus. , Florian Löwenstein, Florian Löwenstein, legt Wert auf Details und Abwechslung: Treffen die Analysen die Erwartungen? Sind die Ergebnisse plausibel? Wo liegt noch Optimierungspotenzial? Der Data Scientist begeistert sich für jeden einzelnen Schritt entlang eines Analyseprojektes und dabei reizt ihn besonders der Austausch mit anderen Fachexperten. Sein liebstes R-Paket ist übrigens sqldf, und Geodaten findet er nicht nur auf Datenebene spannend, sondern auch äußerst ästhetisch.,  - Beitrag vom 08.12.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eine-durchdachte-analysestrategie-ist-wichtiger-als-die-frage-r-oder-python;EODA;
16.11.2017;Das waren die R Kenntnis-Tage 2017;, ×,  - Beitrag vom 16.11.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/das-waren-die-r-kenntnis-tage-2017;EODA;
22.09.2017;Von der Bierpreisbremse bis zur Überwachungssoftware: Eine Analyse der Wahlprogramme;, ×,  - Beitrag vom 22.09.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/von-der-bierpreisbremse-bis-zur-ueberwachungssoftware-eine-analyse-der-wahlprogramme;EODA;
19.09.2017;Case Study: Mit Data Science Betrugsfälle frühzeitig erkennen;, ×,  - Beitrag vom 19.09.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-mit-data-science-betrugsfaelle-fruehzeitig-erkennen;EODA;
15.09.2017;Politik und Daten: Die eoda Shiny-App zur Bundestagswahl 2017;, ×,  - Beitrag vom 15.09.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/politik-und-daten-die-eoda-shiny-app-zur-bundestagswahl-2017;EODA;
24.08.2017;Öffentlich verfügbare Datensätze: Mit VGChartz in das Reich der Videospiele eintauchen;, ×,  - Beitrag vom 24.08.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/oeffentlich-verfuegbare-datensaetze-mit-vgchartz-in-das-reich-der-videospiele-eintauchen;EODA;
09.08.2017;Öffentlich verfügbare Datensätze: Mit GPS-Trajectories die schnellste Route vorhersagen;, ×,  - Beitrag vom 09.08.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/oeffentlich-verfuegbare-datensaetze-mit-gps-trajectories-die-schnellste-route-vorhersagen;EODA;
12.07.2017;Die useR!2017: Unser Fazit;, ×,  - Beitrag vom 12.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user2017-unser-fazit;EODA;
11.07.2017;Case Study: Knowledge-Transfer-Workshop – Shiny-Apps für DB Analytics;, ×,  - Beitrag vom 11.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-knowledge-transfer-workshop-shiny-apps-fuer-db-analytics;EODA;
10.07.2017;Die Highlights der useR!2017: Der Abschlusstag der Konferenz in Brüssel;, ×,  - Beitrag vom 10.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-highlights-der-user2017-der-abschlusstag-der-konferenz-in-bruessel;EODA;
07.07.2017;Die Highlights der useR!2017: Die Eindrücke vom zweiten Konferenztag;, ×,  - Beitrag vom 07.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-highlights-der-user2017-die-eindruecke-vom-zweiten-konferenztag;EODA;
06.07.2017;Die Highlights der useR!2017: Rückblick auf den ersten Konferenztag;, ×,  - Beitrag vom 06.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-highlights-der-user2017-rueckblick-auf-den-ersten-konferenztag;EODA;
05.07.2017;Die Highlights der useR!2017: Der Tutorial-Tuesday;, ×,  - Beitrag vom 05.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-highlights-der-user-2017-der-tutorial-tuesday;EODA;
04.07.2017;„Die useR! Konferenzen sind ein elementarer Bestandteil der R-Community“;, ×,  - Beitrag vom 04.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-konferenzen-sind-ein-elementarer-bestandteil-der-r-community;EODA;
03.07.2017;Case Study: Automatisierte Erstellung von individuellen Reports;, ×,  - Beitrag vom 03.07.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-automatisierte-erstellung-von-individuellen-reports;EODA;
02.06.2017;Die Trendthemen der useR! Conference 2017;, ×,  - Beitrag vom 02.06.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-trendthemen-der-user-conference-2017;EODA;
30.03.2017;Vom optimalen Einstieg bis zur richtigen Kommunikation – Die 12 Erfolgsfaktoren von Data Science;, ×,  - Beitrag vom 30.03.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/vom-optimalen-einstieg-bis-zur-richtigen-kommunikation-die-12-erfolgsfaktoren-von-data-science;EODA;
10.03.2017;5 Praxistipps für anschauliche Datenvisualisierungen;", ×, , R, library, (, forcats, ), boxplot, (, Sepal, ., Width,  , ~,  , Species, ,,  , data,  , =,  , iris, ), iris, $, Species2,  , &amp;, lt, ;, -,  , fct_reorder, (, f,  , =,  , iris, $, Species, ,, x,  , =,  , iris, $, Sepal, ., Width, ,, fun,  , =,  , median, ), boxplot, (, Sepal, ., Width,  , ~,  , Species2, ,,  , data,  , =,  , Iris, ),  - Beitrag vom 10.03.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/old/5-praxistipps-fuer-anschauliche-data-science-visualisierungen;EODA;
03.03.2017;Case Study: Warenkorbanalyse für Schulungsanbieter;, ×,  - Beitrag vom 03.03.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-warenkorbanalyse-fuer-schulungsanbieter;EODA;
16.02.2017;Case Study: Analyse der Erfolgsfaktoren von Einzelhandelsfilialen;, ×,  - Beitrag vom 16.02.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-analyse-der-erfolgsfaktoren-von-einzelhandelsfilialen;EODA;
02.02.2017;Tutorial: So richten Sie mit R einen Twitter-Bot ein;", ×, , R, # Packages ----------------------------------------------------------------, library, (, rvest, ), library, (, stringr, ), library, (, dplyr, ), library, (, twitteR, ), # get number of packages --------------------------------------------------, url,  , &amp;, lt, ;,  , -,  , ""https://cran.r-project.org/web/packages/"", page,  , &amp;, lt, ;, -,  , read_html, (, url, ), n_packages,  , &amp;, lt, ;, -,  , page,  , %, &amp;, gt, ;, %, , html_text, (, ),  , %, &amp;, gt, ;, %,  , , str_extract, (, "":digit:* available packages"", ),  , %, &amp;, gt, ;, %,  , , str_extract, (, "":digit:*"", ),  , %, &amp;, gt, ;, %,  , , as, ., numeric, (, ), n_packages_last_time,  , &amp;, lt, ;,  , -,  , read, ., table, (, file,  , =,  , ""n_packages.csv"", ,, stringsAsFactors,  , =,  , F, ,,  , sep,  , =,  , "";"", ), n_packages_last_time,  , &amp;, lt, ;, -,  , n_packages_last_time, $, V2, , nrow, (, n_packages_last_time, ), ,  , ## check if news packages are published, new tweet only when number of packages changed if(n_packages &amp;ampgt n_packages_last_time) {, , , # Twitter -----------------------------------------------------------------, , , # set up twitter api, , api_keys,  , &amp;, lt, ;,  , -,  , read, ., csv2, (, ""twitter_access.csv"", ,,  , stringsAsFactors,  , =,  , FALSE, ), , , setup_twitter_oauth, (, consumer_key,  , =,  , api_keys, $, consumer_key, ,, , consumer_secret,  , =,  , api_keys, $, consumer_secret, ,, , access_token,  , =,  , api_keys, $, access_token, ,, , access_secret,  , =,  , api_keys, $, access_secret, ), , , , , time,  , &amp;, lt, ;, -,  , Sys, ., time, (, ), , , # create tweet, , tweet_text,  , &amp;, lt, ;, -,  , paste0, (, ""#Rstatsgoes10k - Hello World, it's "", ,,  , time, ,,  , "" and currently there are "", ,,  , n_packages, ,,  , "" packages on CRAN. "", ), , , # send tweet, , tweet, (, tweet_text, ), , , , # write n to file ---------------------------------------------------------, , , n_packages_df,  , &amp;, lt, ;, -,  , data, ., frame, (, time,  , =,  , Sys, ., time, (, ), ,,  , n,  , =,  , n_packages, ), , , write, ., table, (, n_packages_df, ,,  , file,  , =,  , ""n_packages.csv"", ,,  , row, ., names,  , =,  , FALSE, ,, col, ., names,  , =,  , FALSE, ,, , append,  , =,  , TRUE, ,,  , sep,  , =,  , "";"", ), , },  - Beitrag vom 02.02.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/old/tutorial-so-richten-sie-mit-r-einen-twitter-bot-ein;EODA;
28.01.2017;Zum 10.000. R-Paket: Die eoda Top 10;, ×,  - Beitrag vom 28.01.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/zum-10-000-r-paket-die-eoda-top-10;EODA;
24.01.2017;#Rstatsgoes10k – So errechnete eoda den Tag des 10.000sten Pakets;", ×, , R, # Bereinigung und Aufbereitung der Daten., df_archive,  , &amp;, lt, ;,  , -,  , as, ., data, ., frame, (, cran_archive, ), df_cran,  , &amp;, lt, ;, -,  , as, ., data, ., frame, (, cran_by_date, ),  , df_archive,  , &amp;, lt, ;, -,  , df_archive, , -, 1, :, -, 2, ,,  , , df_archive,  , &amp;, lt, ;, -,  , df_archive, , ,,  , c, (, -, 1, ,,  , -, 4, ,,  , -, 5, ), , df_cran,  , &amp;, lt, ;, -,  , df_cran, , ,,  , 1, :, 2, ,  , df_cran,  , &amp;, lt, ;, -,  , data, ., frame, (, date,  , =,  , df_cran, , ,,  , 1, , ,,  , package,  , =,  , df_cran, , ,,  , 2, , ), df_archive,  , &amp;, lt, ;, -,  , data, ., frame, (, date,  , =,  , df_archive, , ,,  , 2, , ,,  , package,  , =,  , df_archive, , ,,  , 1, , ),  , df_cran, $, date,  , &amp;, lt, ;, -,  , as, ., Date, (, df_cran, $, date, ), df_archive, $, date,  , &amp;, lt, ;, -,  , as, ., character, (, df_archive, $, date, ),  , df_archive, $, package,  , &amp;, lt, ;, -,  , gsub, (, ""/"", ,,  , """", ,,  , df_archive, $, package, ), df_archive, $, date,  , &amp;, lt, ;, -,  , gsub, (, "" .*"", ,,  , """", ,,  , df_archive, $, date, ),  , df,  , &amp;, lt, ;, -,  , rbind, (, df_cran, ,,  , df_archive, ),  , # Löschen aller Pakete aus dem cran Datensatz die auch im Archiv vorhanden , # sind., library, (, dplyr, ), df_new,  , &amp;, lt, ;, -,  , df,  , %, &amp;, gt, ;, %,  , group_by, (, package, ),  , %, &amp;, gt, ;, %,  , filter, (, n, (, ),  , ==,  , 1, ), , R, # Auswahl des Beobachtungszeitraums. Hier 30 Tage., df_tail,  , &amp;, lt, ;,  , -,  , tail, (, data, ., frame, (, table, (, df_new, $, date, ), ), ,,  , 30, ), df_tail, $, cum,  , &amp;, lt, ;, -,  , cumsum, (, df_tail, $, Freq, ),  , # Anwenden von forecast mit Vorhersage für die nächsten 30 Tage., df_forecast,  , &amp;, lt, ;, -,  , forecast, (, df_tail, $, cum, ,,  , 30, ), summary, (, df_forecast, ), , R, # Anzahl der Pakete bis zur 10000 Pakete Marke für den Teildatensatz. In , # diesem Fall 368., 10000,  , -,  , (, length, (, df_cran, $, date, ),  , -,  , max, (, df_tail, $, cum, ), ), aim_packages,  , &amp;, lt, ;,  , -,  , 10000,  , -,  , (, length, (, df_cran, $, date, ),  , -,  , max, (, df_tail, $, cum, ), ),  , # Das Ergebnis als Plot mit 10000 Pakete Schwelle, minimum Grenze, # Mittelwert und Maximale Anzahl an Tagen. plot(df_forecast) abline(a = aim_packages, b = 0, lty = 1, col = ""black"", lwd = 3) lines(c(min(which(df_forecast$lower, 2 &amp;ampgt aim_packages)) - 1 + 30, min(which(df_forecast$lower, 2 &amp;ampgt aim_packages)) - 1 + 30), c(0, 500)), lines, (, c, (, min, (, which, (, df_forecast, $, upper, , ,,  , 2, ,  , &amp;, gt, ;,  , aim_packages, ), ),  , -,  , 1,  , +,  , 30, ,,  , min, (, which, (, df_forecast, $, upper, , ,,  , 2, ,  , &amp;, gt, ;,  , aim_packages, ), ),  , -,  , 1,  , +,  , 30, ), ,,  , c, (, 0, ,,  , 500, ), ), lines, (, c, (, min, (, which, (, df_forecast, $, mean,  , &amp;, gt, ;,  , aim_packages, ), ),  , -,  , 1,  , +,  , 30, ,,  , min, (, which, (, df_forecast, $, mean,  , &amp;, gt, ;,  , aim_packages, ), ),  , -,  , 1,  , +,  , 30, ), ,,  , c, (, 0, ,,  , 500, ), ), , R, # Der Tag an dem die 368, also 10000, Pakete erreicht werden., df_forecast, $, mean, , min, (, which, (, df_forecast, $, mean,  , &amp;, gt, ;,  , aim_packages, ), ),  , -,  , 1, , # Stichtag 2.1. + 25 Tage = 27.1.2017, , R, # Mit den Daten vom Twitter-Bot und linearer Regression, df_twitter,  , &amp;, lt, ;,  , -,  , data, ., frame, (, day,  , =,  , c, (, 0, ,,  , 5, ,,  , 6, ,,  , 7, ,,  , 8, ,,  , 9, ,,  , 10, ,,  , 11, ), ,,  , packages,  , =,  , c, (, 9763, ,,  , 9787, ,,  , 9799, ,,  , 9808, ,,  , 9814, ,,  , 9823, ,,  , 9828, ,,  , 9832, ), ),  , lm1,  , &amp;, lt, ;, -,  , lm, (, packages,  , ~,  , day, ,,  , df_twitter, ), # Wieder 2.1. + 25 Tage = 27.1.2017, (, 10000,  , -,  , max, (, df_twitter, $, packages, ), ),  , /,  , coefficients, (, lm1, ), , 2, ,  , +,  , 2,  - Beitrag vom 24.01.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/old/rstatsgoes10k-so-errechnete-eoda-den-tag-des-10-000sten-pakets;EODA;
20.01.2017;Case Study: Automatische Kategorisierung von Antworten bei Kundenbefragung für die OBI Group;, ×,  - Beitrag vom 20.01.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-automatische-kategorisierung-von-antworten-bei-kundenbefragung-fuer-die-obi-group;EODA;
16.01.2017;Meetups: Data Science im Fokus;, ×,  - Beitrag vom 16.01.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/meetups-data-science-im-fokus;EODA;
10.01.2017;Big Data aus der Sicht eines Data Scientist;, ×, , , , , , ,  - Beitrag vom 10.01.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/big-data-aus-der-sicht-eines-data-scientist;EODA;
05.01.2017;#Rstatsgoes10k: Mit unserem Twitter-Bot bleiben Sie immer auf dem neuesten Pakete-Stand!;, ×,  - Beitrag vom 05.01.2017, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/rstatsgoes10k-mit-unserem-twitterbot-bleiben-sie-immer-auf-dem-neuesten-pakete-stand;EODA;
22.12.2016;#Rstatsgoes10k – eoda feiert das 10.000 R-Paket mit einem Gewinnspiel;, ×,  - Beitrag vom 22.12.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/rstatsgoes10k-eoda-feiert-das-10-000-r-paket-mit-einem-gewinnspiel;EODA;
21.12.2016;Es ist amtlich – Der Weihnachtsmann ist Data Scientist;, ×, eoda wünscht allen frohe Weihnachten und einen guten Rutsch ins neue Jahr.,  - Beitrag vom 21.12.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/es-ist-amtlich-der-weihnachtsmann-ist-data-scientist;EODA;
25.11.2016;Digitales Lernen: eoda auf DataCamp;, ×,  - Beitrag vom 25.11.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/digitales-lernen-eoda-auf-datacamp;EODA;
24.11.2016;Professioneller Support für die Anwender von Open Source R;, ×,  - Beitrag vom 24.11.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/professioneller-support-fuer-die-anwender-von-open-source-r;EODA;
10.11.2016;Ein voller Erfolg: Die R Kenntnis-Tage 2016;, ×,  - Beitrag vom 10.11.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/ein-voller-erfolg-die-r-kenntnis-tage-2016;EODA;
01.11.2016;Case Study: Präzise Prognosemodelle für 50Hertz;, ×,  - Beitrag vom 01.11.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-praezise-prognosemodelle-fuer-50hertz;EODA;
21.10.2016;Case Study: Optimierung des Aktionsgeschäfts für einen internationalen Retailer;, ×, Um seine Marktposition zu festigen und Kaufanreize für seine Kunden zu schaffen, investiert ein Einzelhändler wöchentlich einen Teil seines Umsatzes in das Aktionsgeschäft und bietet bestimmte Artikel seines Warensortiments zu reduzierten Preisen an. Im Hinblick auf die Planung dieser Aktionen existiert bislang nur wenig gesichertes Wissen darüber, welche Faktoren über den Erfolg entscheiden., Die Grundlage der Analysen sind Daten mit einem Gesamtvolumen von mehreren Terrabyte. Durch die Verknüpfung verschiedener Datenquellen –Transaktionen auf Kassenbon-Ebene, Stammdaten, Aktionsmerkmale und externe Informationen wie Feiertage –kann ein umfassender Einblick in das Aktionsgeschäft gewonnen werden.,  - Beitrag vom 21.10.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-optimierung-des-aktionsgeschaefts-fuer-einen-internationalen-retailer;EODA;
18.10.2016;eRum 2016: Ein gelungenes Aufeinandertreffen der europäischen R Heroes;, ×, Slideshare, GitHub,  - Beitrag vom 18.10.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/erum-2016-ein-gelungenes-aufeinandertreffen-der-europaeischen-r-heroes;EODA;
08.09.2016;Einsatzmöglichkeiten von Data Science in der Lasertechnik;, ×,  - Beitrag vom 08.09.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/einsatzmoeglichkeiten-von-data-science-in-der-lasertechnik;EODA;
06.09.2016;Die Tabelle lügt nie!? Profifußball als Anwendungsfall von Data Science;, ×,  - Beitrag vom 06.09.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-tabelle-luegt-nie-profifussball-als-anwendungsfall-von-data-science;EODA;
05.09.2016;Case Study: Kundenanalyse für die VR Bank Werra-Meißner eG;, ×,  - Beitrag vom 05.09.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-kundenanalyse-fuer-die-vr-bank-werra-meissner-eg;EODA;
30.08.2016;Multidimensionales Clustering mit Webanalysedaten;, ×,  - Beitrag vom 30.08.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/multidimensionales-clustering-mit-webanalysedaten;EODA;
30.08.2016;Effizientes Arbeiten mit R – Schneller zum Data Product;, ×,  - Beitrag vom 30.08.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/effizientes-arbeiten-mit-r-schneller-zum-data-product;EODA;
29.07.2016;Open Source im Trend: R löst SAS als beliebtestes Analysetool ab;, ×,  - Beitrag vom 29.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/open-source-im-trend-r-loest-sas-als-beliebtestes-analysetool-ab;EODA;
27.07.2016;Case Study: Entwicklung eines Scoring-Algorithmus für die databyte®GmbH;, ×, Die databyte, ®, GmbH stellt Ihren Auftraggebern umfangreiche Wirtschaftsinformationen u.a. für die Neukundengewinnung bereit. Insgesamt sind mehr als 5 Millionen Gewerbetreibende mit mehr als 100 Millionen Zusatzinformationen verfügbar. Die Passgenauigkeit der für die Neukundengewinnung zu identifizierenden Zielgruppenpotenziale ist dabei das entscheidende Qualitätskriterium., Um die bereits gute Passgenauigkeit weiter zu erhöhen, soll ein Scoring-Algorithmus entwickelt werden, der auf Basis von Bestandskundenlisten Neukundenpotenziale mit möglichst hoher Abschlusswahrscheinlichkeit ermittelt. , Bestandskundenlisten wurden zunächst nach Branchen segmentiert. Für die entstandenen Branchensegmente hat eoda unter Einbeziehung einer Vielzahl unterschiedlicher Informationen wie Umsatz, Mitarbeiteranzahl und der bisherigen Branchen-Affinität Kundenprofile entwickelt. Um Rückschlüsse für die Neukundengewinnung ziehen zu können, hat eoda die Datenbankeinträge anschließend auf Übereinstimmungen mit den Kundenprofilen untersucht., Das Ergebnis ist eine Übersicht aller Firmen mit kundenindividuellen Score-Werten, die am besten in das Kundenprofil des Auftraggebers passen und eine hohe Kaufwahrscheinlichkeit aufweisen. Dies erhöht die Effizienz der Neukundenakquise und senkt dank geringerer Streuverluste gleichzeitig die Kosten., ®, GmbH,  - Beitrag vom 27.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/case-study-entwicklung-eines-scoring-algorithmus-fuer-die-databytegmbh;EODA;
26.07.2016;Anwendungen und Schnittstellen für Data Science: Microsofts R-Portfolio;, ×,  - Beitrag vom 26.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/anwendungen-und-schnittstellen-fuer-data-science-microsofts-r-portfolio;EODA;
26.07.2016;Dabei sein ist (nicht) alles: Deutsche Medaillengewinne bei Olympischen Sommerspielen;, ×,  - Beitrag vom 26.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/dabei-sein-ist-nicht-alles-deutsche-medaillengewinne-bei-olympischen-sommerspielen;EODA;
22.07.2016;Rückblick auf das Summer Meetup der Kasseler useR Group;, ×,  - Beitrag vom 22.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/rueckblick-auf-das-summer-meetup-der-kasseler-user-group;EODA;
22.07.2016;Die useR! Conference 2016 in Stanford: Ein Fazit;, ×,  - Beitrag vom 22.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-ein-fazit;EODA;
08.07.2016;Die useR! Conference 2016 in Stanford: Die Höhepunkte vom dritten Präsentationstag;, ×,  - Beitrag vom 08.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-die-hoehepunkte-vom-dritten-praesentationstag;EODA;
05.07.2016;eRum 2016: Die erste europäische Konferenz für die Programmiersprache R;, ×,  - Beitrag vom 05.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/erum-2016-die-erste-europaeische-konferenz-fuer-die-programmiersprache-r;EODA;
05.07.2016;Die useR! Conference 2016 in Stanford: Die Highlights vom zweiten Präsentationstag;, ×,  - Beitrag vom 05.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-die-highlights-vom-zweiten-praesentationstag;EODA;
04.07.2016;Die useR! Conference 2016 in Stanford: Keynote Simon Urbanek;, ×,  - Beitrag vom 04.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-keynote-simon-urbanek;EODA;
01.07.2016;Die useR! Conference 2016 in Stanford: Keynote Deborah Nolan;, ×,  - Beitrag vom 01.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-keynote-deborah-nolan;EODA;
01.07.2016;Die useR! Conference 2016 in Stanford: Keynote von Daniela Witten;, ×,  - Beitrag vom 01.07.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-keynote-von-daniela-witten;EODA;
30.06.2016;Die useR! Conference 2016 in Stanford: Keynote von Hadley Wickham;, ×,  - Beitrag vom 30.06.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-keynote-von-hadley-wickham;EODA;
29.06.2016;Die useR! Conference 2016 in Stanford: Die Highlights vom ersten Präsentationstag;, ×,  - Beitrag vom 29.06.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2016-in-stanford-die-highlights-vom-ersten-praesentationstag;EODA;
29.06.2016;Die useR! Conference 2016 in Stanford: Die Highlights der ersten Keynote;, ×,  - Beitrag vom 29.06.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2016-in-stanford-die-highlights-der-ersten-keynote;EODA;
28.06.2016;Die useR! Conference 2016 in Stanford: Der „Tutorial Monday“;, ×,  - Beitrag vom 28.06.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2016-in-stanford-der-tutorial-monday;EODA;
16.06.2016;EXASOL und R: Performante Kombination für die Anforderungen von Big Data;, ×,  - Beitrag vom 16.06.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/exasol-und-r-performante-kombination-fuer-die-anforderungen-von-big-data;EODA;
10.06.2016;Data Science operationalisieren: eoda präsentiert auf der useR! Conference 2016 in Stanford;, ×,  - Beitrag vom 10.06.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-operationalisieren-eoda-praesentiert-auf-der-user-conference-2016-in-stanford;EODA;
13.05.2016;Data Mining Demo: Modellbildung und Prognose mit R und Exasol;", ×, , R, # Laden der benötigten Pakete, library, (, RODBC, ), library, (, exasol, ), library, (, rredis, ), library, (, magrittr, ), library, (, stringi, ), library, (, rpart, ), library, (, partykit, ), # Verbindung zu Exasol und Redis herstellen, con,  , &amp;, lt, ;,  , -,  , odbcConnect, (, ""exasol_vm"", ), redisConnect, (, ""172.20.248.13"", ), # Erstellen eines Zufallszahlen-Vektors für die Stichprobenziehung, rnd,  , &amp;, lt, ;, -,  , rnorm, (, nrow, (, iris, ), ), # Anfügen der Gruppenvariable (Training/Validierung), iris, $, groups,  , &amp;, lt, ;, -,  , factor, (, NA, ,,  , levels,  , =,  , c, (, ""Train"", ,,  , ""Valid"", ), ), # Nach Spezies geschichtete Zufallsziehung: 70% Training, 30% Validierung, for, (, i,  , in,  , unique, (, iris, $, Species, ), ),  , {, , logVec,  , &amp;, lt, ;, -,  , iris, $, Species,  , ==,  , i, , iris, $, groups, , logVec, ,  , &amp;, lt, ;, -,  , ifelse, (, test,  , =,  , rnd, , logVec, ,  , &amp;, gt, ;,  , quantile, (, rnd, , logVec, , ,,  ,  , probs,  , =,  , 0.3, ), ,, , yes,  , =,  , ""Train"", ,, , no,  , =,  , ""Valid"", ),  , }, # Überprüfung der Stichprobenziehung, table, (, iris, $, groups, ,,  , iris, $, Species, ), # Workspace aufräumen, rm, (, rnd, ,,  , logVec, ,,  , i, ), , R, # Datenbankschema mit dem Namen &lt;em&gt;my_schema&lt;/em&gt; erstellen, odbcQuery, (, con, ,,  , ""create schema my_schema"", ), # Erstellen der leeren Tabelle unter dem Namen &lt;em&gt;irisdb&lt;/em&gt;, odbcQuery, (, con, ,,  , ""create or replace table my_schema.irisdb(,  SepalLength DOUBLE, ,  SepalWidth DOUBLE, ,  PetalLength DOUBLE, ,  PetalWidth DOUBLE, ,  Species CHAR(20),,  Groups CHAR(20));"", ), # Hochladen der &lt;em&gt;iris&lt;/em&gt; Daten in die Exasol, exa, ., writeData, (, con, ,,  , data,  , =,  , iris, ,,  , tableName,  , =,  , ""my_schema.irisdb"", ), , R, # Erstellen eines Trainings- und eines Validierungsdatensatzes, train,  , &amp;, lt, ;,  , -,  , subset, (, iris, ,,  , subset,  , =,  , groups,  , ==,  , ""Train"", ,,  , select,  , =,  , -, groups, ), valid,  , &amp;, lt, ;, -,  , subset, (, iris, ,,  , subset,  , =,  , groups,  , ==,  , ""Valid"", ,,  , select,  , =,  , -, groups, ), # Erstellen des Entscheidungsbaums mit den Trainingsdaten, localTree,  , &amp;, lt, ;, -,  , rpart, (, Species,  , ~,  , ., ,,  , data,  , =,  , train, ), # Visualisierung des Baums, plot, (, as, ., party, (, localTree, ), ), # Prognose Validierungsdaten mit Hilfe des Baums , pred,  , &amp;, lt, ;, -,  , predict, (, localTree, ,,  , type,  , =,  , ""class"", ,,  , newdata,  , =,  , valid, ),  , # Prognose überprüfen table(pred, valid$Species, dnn = c(""Vorhersage"", ""Tatsächlich"")) %&amp;ampgt% , , addmargins, (, ), , R, exa_rf,  , &amp;, lt, ;,  , -,  , exa, ., createScript, (, , con, ,,  , , ""my_schmea.exa_rf"", ,,  , # Unter diesem Namen ist das R-Script über SQL verfügbar, , function, (, data, ),  , {, , , # Laden der benötigten Pakete. Diese müssen ggf. in der Exasol installiert sein, , require, (, rpart, ), , require, (, stringi, ), , require, (, rredis, ), , , # Verbindung mit Redis , , redisConnect, (, ""172.20.248.13"", ,,  , port,  , =,  , 6379, ), , , # Laden aller Daten aus der Exasol Tabelle, , # wird im Funktionsaufruf das &lt;em&gt;groupBy oder &lt;/em&gt;&lt;em&gt;where&lt;/em&gt; Argument verwendet,, , # wird nur der entsprechende Teil der Daten geladen., , data, $, next_row, (, NA, ), , , # Wandeln des &lt;em&gt;data&lt;/em&gt; Objekts in einen &lt;em&gt;data.frame&lt;/em&gt;, , df,  , &amp;, lt, ;,  , -,  , data, ., frame, (, v1,  , =,  , data, $, SepalLength, ,,  , v2,  , =,  , data, $, SepalWidth, ,,  , v3,  , =,  , data, $, PetalLength, ,,  , v4,  , =,  , data, $, PetalWidth, ,,  , species,  , =,  , data, $, Species, ), , , # Aufbereiten des data.frames, , df, $, species,  , &amp;, lt, ;, -,  , stri_replace_all_fixed, (, df, $, species, ,,  , "" "", ,,  , """", ), , df, $, species,  , &amp;, lt, ;, -,  , as, ., factor, (, df, $, species, ), , , , # Erstellen des Baums, , rf,  , &amp;, lt, ;, -,  , rpart, (, species,  , ~,  , ., ,,  , data,  , =,  , df, ), , , # Speichern des Baums in Redis , , redisSet, (, ""exa_rf"", ,,  , rf, ), , , # Rückgabe der Zeilenanzahl (zur Kontrolle), , data, $, emit, (, nrow, (, df, ), ), , }, ,, , inArgs,  , =,  , c, (, ""SepalLength DOUBLE"", ,,  , , ""SepalWidth DOUBLE"", ,,  , , ""PetalLength DOUBLE"", ,, , ""PetalWidth DOUBLE"", ,, , ""Species CHAR(20)"", ), ,, , outArgs,  , =,  , ""Feedback INT"", ), # Aufrufen der oben gebildeten Funktion. Das where Argument legt fest, dass , # das Modell auf den Trainingsdaten gebildet wird. , exa_rf, (, ""SepalLength"", ,,  , ""SepalWidth"", ,,  , ""PetalLength"", ,,  , ""PetalWidth"", ,,  , ""Species"", ,,  , table,  , =,  , ""my_schema.irisdb"", ,,  ,  , where,  , =,  , ""groups = 'Train'"", ), , R, exa_predict_rf,  , &amp;, lt, ;,  , -,  , exa, ., createScript, (, , con, ,, , ""my_schema.exa_pred"", ,, , function, (, data, ),  , {, , , require, (, rpart, ), , require, (, rredis, ), , , redisConnect, (, ""172.20.248.13"", ,,  , port,  , =,  , 6379, ), , , data, $, next_row, (, NA, ), , , df,  , &amp;, lt, ;, -,  , data, ., frame, (, v1,  , =,  , data, $, SepalLength, ,,  , v2,  , =,  , data, $, SepalWidth, ,,  , v3,  , =,  , data, $, PetalLength, ,,  , v4,  , =,  , data, $, PetalWidth, ,,  , species,  , =,  , data, $, Species, ), , , # Laden des Baum Modells aus Redis, , rf,  , &amp;, lt, ;, -,  , redisGet, (, ""exa_rf"", ),  , , , # Erstellen der Prognose, , pred,  , &amp;, lt, ;, -,  , predict, (, rf, ,,  , newdata,  , =,  , df, ,,  , type,  , =,  , ""class"", ), , , # Rückgabe der Prognose sowie der echten Klassenzugehörigkeit, , data, $, emit, (, pred, ,,  , df, $, species, ), , }, ,, , inArgs,  , =,  , c, (,  , ""SepalLength DOUBLE"", ,,  , , ""SepalWidth DOUBLE"", ,,  , , ""PetalLength DOUBLE"", ,, , ""PetalWidth DOUBLE"", ,, , ""Species CHAR(20)"", ), ,, , outArgs,  , =,  , c, (, ""Prognose CHAR(20)"", ,, , ""Realwerte CHAR(20)"", ), ), # Aufruf der oben gebildeten Funktion. Die Rückgabe wird in ein Objekt gespeichert. , exa_pred,  , &amp;, lt, ;, -,  , exa_predict_rf, (, ""SepalLength"", ,,  , ""SepalWidth"", ,,  , ""PetalLength"", ,,  , ""PetalWidth"", ,,  , ""Species"", ,,  , table,  , =,  , ""my_schema.irisdb"", ,,  , where,  , =,  , ""groups = 'Valid'"", ),  , # Mit Hilfe der Table Funktion kann geprüft werden, wie gut die Prognose performt. table(exa_pred$PROGNOSE, exa_pred$REALWERTE, dnn = c(""Prognose"", ""Realwerte"")) %&amp;ampgt% , , addmargins, (, ), , R, # Laden der benötigten Pakete, library, (, RODBC, ), library, (, exasol, ), library, (, rredis, ), library, (, magrittr, ), library, (, stringi, ), library, (, rpart, ), library, (, partykit, ), # Verbindung zu Exasol und Redis herstellen, con,  , &amp;, lt, ;,  , -,  , odbcConnect, (, ""exasol_vm"", ), redisConnect, (, ""172.20.248.13"", ), # Erstellen eines Zufallszahlen-Vektors für die Stichprobenziehung, rnd,  , &amp;, lt, ;, -,  , rnorm, (, nrow, (, iris, ), ), # Anfügen der Gruppenvariable (Training/Validierung), iris, $, groups,  , &amp;, lt, ;, -,  , factor, (, NA, ,,  , levels,  , =,  , c, (, ""Train"", ,,  , ""Valid"", ), ), # Nach Spezies geschichtete Zufallsziehung: 70% Training, 30% Validierung, for, (, i,  , in,  , unique, (, iris, $, Species, ), ),  , {, , logVec,  , &amp;, lt, ;, -,  , iris, $, Species,  , ==,  , i, , iris, $, groups, , logVec, ,  , &amp;, lt, ;, -,  , ifelse, (, test,  , =,  , rnd, , logVec, ,  , &amp;, gt, ;,  , quantile, (, rnd, , logVec, , ,,  ,  , probs,  , =,  , 0.3, ), ,, , yes,  , =,  , ""Train"", ,, , no,  , =,  , ""Valid"", ),  , }, # Überprüfung der Stichprobenziehung, table, (, iris, $, groups, ,,  , iris, $, Species, ), # Workspace aufräumen, rm, (, rnd, ,,  , logVec, ,,  , i, ), , R, # Datenbankschema mit dem Namen &lt;em&gt;my_schema&lt;/em&gt; erstellen, odbcQuery, (, con, ,,  , ""create schema my_schema"", ), # Erstellen der leeren Tabelle unter dem Namen &lt;em&gt;irisdb&lt;/em&gt;, odbcQuery, (, con, ,,  , ""create or replace table my_schema.irisdb(,  SepalLength DOUBLE, ,  SepalWidth DOUBLE, ,  PetalLength DOUBLE, ,  PetalWidth DOUBLE, ,  Species CHAR(20),,  Groups CHAR(20));"", ), # Hochladen der &lt;em&gt;iris&lt;/em&gt; Daten in die Exasol, exa, ., writeData, (, con, ,,  , data,  , =,  , iris, ,,  , tableName,  , =,  , ""my_schema.irisdb"", ), , R, # Erstellen eines Trainings- und eines Validierungsdatensatzes, train,  , &amp;, lt, ;,  , -,  , subset, (, iris, ,,  , subset,  , =,  , groups,  , ==,  , ""Train"", ,,  , select,  , =,  , -, groups, ), valid,  , &amp;, lt, ;, -,  , subset, (, iris, ,,  , subset,  , =,  , groups,  , ==,  , ""Valid"", ,,  , select,  , =,  , -, groups, ), # Erstellen des Entscheidungsbaums mit den Trainingsdaten, localTree,  , &amp;, lt, ;, -,  , rpart, (, Species,  , ~,  , ., ,,  , data,  , =,  , train, ), # Visualisierung des Baums, plot, (, as, ., party, (, localTree, ), ), # Prognose Validierungsdaten mit Hilfe des Baums , pred,  , &amp;, lt, ;, -,  , predict, (, localTree, ,,  , type,  , =,  , ""class"", ,,  , newdata,  , =,  , valid, ),  , # Prognose überprüfen table(pred, valid$Species, dnn = c(""Vorhersage"", ""Tatsächlich"")) %&amp;ampgt% , , addmargins, (, ), , R, exa_rf,  , &amp;, lt, ;,  , -,  , exa, ., createScript, (, , con, ,,  , , ""my_schmea.exa_rf"", ,,  , # Unter diesem Namen ist das R-Script über SQL verfügbar, , function, (, data, ),  , {, , , # Laden der benötigten Pakete. Diese müssen ggf. in der Exasol installiert sein, , require, (, rpart, ), , require, (, stringi, ), , require, (, rredis, ), , , # Verbindung mit Redis , , redisConnect, (, ""172.20.248.13"", ,,  , port,  , =,  , 6379, ), , , # Laden aller Daten aus der Exasol Tabelle, , # wird im Funktionsaufruf das &lt;em&gt;groupBy oder &lt;/em&gt;&lt;em&gt;where&lt;/em&gt; Argument verwendet,, , # wird nur der entsprechende Teil der Daten geladen., , data, $, next_row, (, NA, ), , , # Wandeln des &lt;em&gt;data&lt;/em&gt; Objekts in einen &lt;em&gt;data.frame&lt;/em&gt;, , df,  , &amp;, lt, ;,  , -,  , data, ., frame, (, v1,  , =,  , data, $, SepalLength, ,,  , v2,  , =,  , data, $, SepalWidth, ,,  , v3,  , =,  , data, $, PetalLength, ,,  , v4,  , =,  , data, $, PetalWidth, ,,  , species,  , =,  , data, $, Species, ), , , # Aufbereiten des data.frames, , df, $, species,  , &amp;, lt, ;, -,  , stri_replace_all_fixed, (, df, $, species, ,,  , "" "", ,,  , """", ), , df, $, species,  , &amp;, lt, ;, -,  , as, ., factor, (, df, $, species, ), , , , # Erstellen des Baums, , rf,  , &amp;, lt, ;, -,  , rpart, (, species,  , ~,  , ., ,,  , data,  , =,  , df, ), , , # Speichern des Baums in Redis , , redisSet, (, ""exa_rf"", ,,  , rf, ), , , # Rückgabe der Zeilenanzahl (zur Kontrolle), , data, $, emit, (, nrow, (, df, ), ), , }, ,, , inArgs,  , =,  , c, (, ""SepalLength DOUBLE"", ,,  , , ""SepalWidth DOUBLE"", ,,  , , ""PetalLength DOUBLE"", ,, , ""PetalWidth DOUBLE"", ,, , ""Species CHAR(20)"", ), ,, , outArgs,  , =,  , ""Feedback INT"", ), # Aufrufen der oben gebildeten Funktion. Das where Argument legt fest, dass , # das Modell auf den Trainingsdaten gebildet wird. , exa_rf, (, ""SepalLength"", ,,  , ""SepalWidth"", ,,  , ""PetalLength"", ,,  , ""PetalWidth"", ,,  , ""Species"", ,,  , table,  , =,  , ""my_schema.irisdb"", ,,  ,  , where,  , =,  , ""groups = 'Train'"", ), , R, exa_predict_rf,  , &amp;, lt, ;,  , -,  , exa, ., createScript, (, , con, ,, , ""my_schema.exa_pred"", ,, , function, (, data, ),  , {, , , require, (, rpart, ), , require, (, rredis, ), , , redisConnect, (, ""172.20.248.13"", ,,  , port,  , =,  , 6379, ), , , data, $, next_row, (, NA, ), , , df,  , &amp;, lt, ;, -,  , data, ., frame, (, v1,  , =,  , data, $, SepalLength, ,,  , v2,  , =,  , data, $, SepalWidth, ,,  , v3,  , =,  , data, $, PetalLength, ,,  , v4,  , =,  , data, $, PetalWidth, ,,  , species,  , =,  , data, $, Species, ), , , # Laden des Baum Modells aus Redis, , rf,  , &amp;, lt, ;, -,  , redisGet, (, ""exa_rf"", ),  , , , # Erstellen der Prognose, , pred,  , &amp;, lt, ;, -,  , predict, (, rf, ,,  , newdata,  , =,  , df, ,,  , type,  , =,  , ""class"", ), , , # Rückgabe der Prognose sowie der echten Klassenzugehörigkeit, , data, $, emit, (, pred, ,,  , df, $, species, ), , }, ,, , inArgs,  , =,  , c, (,  , ""SepalLength DOUBLE"", ,,  , , ""SepalWidth DOUBLE"", ,,  , , ""PetalLength DOUBLE"", ,, , ""PetalWidth DOUBLE"", ,, , ""Species CHAR(20)"", ), ,, , outArgs,  , =,  , c, (, ""Prognose CHAR(20)"", ,, , ""Realwerte CHAR(20)"", ), ), # Aufruf der oben gebildeten Funktion. Die Rückgabe wird in ein Objekt gespeichert. , exa_pred,  , &amp;, lt, ;, -,  , exa_predict_rf, (, ""SepalLength"", ,,  , ""SepalWidth"", ,,  , ""PetalLength"", ,,  , ""PetalWidth"", ,,  , ""Species"", ,,  , table,  , =,  , ""my_schema.irisdb"", ,,  , where,  , =,  , ""groups = 'Valid'"", ),  , # Mit Hilfe der Table Funktion kann geprüft werden, wie gut die Prognose performt. table(exa_pred$PROGNOSE, exa_pred$REALWERTE, dnn = c(""Prognose"", ""Realwerte"")) %&amp;ampgt% , , addmargins, (, ),  - Beitrag vom 13.05.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/old/dataming-demo-modellbildung-und-prognose-mit-r-und-exasol-2;EODA;
13.05.2016;R und Exasol: Installation und Konfiguration der benötigten Komponenten;", ×, Wichtig ist, die http Variante statt der https Veriante zu verwenden (im Beispiel: https://cran.uni-muenster.de), Es können nur Pakete verwendet werden, die R Versionen nicht größer als derzeit 3.0.2 voraussetzen, , R, # Zu installierende Pakete festlegen..., pkg,  , &amp;, lt, ;,  , -,  , c, (, ""RODBC"", ,,  , ""rredis"", ,,  , ""stringi"", ,,  , ""magrittr"", ,,  , ""rpart"", ,,  , ""partykit"", ,,  , ""devtools"", ), install, ., packages, (, pkg, ), Das , Paket,  , 'devtools',  , muss , geladen , werden, ,,  , bevor , Exasol , von , Github , installiert , werden , kann, library, (, devtools, ), install_github, (, ""EXASOL/r-exasol"", ), #Laden der übrigen Pakete, library, (, RODBC, ), library, (, rredis, ), library, (, exasol, ), library, (, stringi, ), library, (, magrittr, ), library, (, rpart, ), library, (, partykit, ), , R, # Erstellen des Verbindungsobjekts, con,  , &amp;, lt, ;,  , -,  , odbcConnect, (, ""exasol_vm"", ), # Verbinden mit Redis, redisConnect, (, ""172.20.248.13"", ), A,  , &amp;, lt, ;, -,  , 2, # Speichern von A in Redis, redisSet, (, ""Test"", ,,  , A, ), # Entfernen von A , rm, (, A, ), # Wenn der Wert 2 angezeigt wird, steht die Verbindung zu Redis , redisGet, (, ""Test"", ), Wichtig ist, die http Variante statt der https Veriante zu verwenden (im Beispiel: https://cran.uni-muenster.de), Es können nur Pakete verwendet werden, die R Versionen nicht größer als derzeit 3.0.2 voraussetzen, , R, # Zu installierende Pakete festlegen..., pkg,  , &amp;, lt, ;,  , -,  , c, (, ""RODBC"", ,,  , ""rredis"", ,,  , ""stringi"", ,,  , ""magrittr"", ,,  , ""rpart"", ,,  , ""partykit"", ,,  , ""devtools"", ), install, ., packages, (, pkg, ), Das , Paket,  , 'devtools',  , muss , geladen , werden, ,,  , bevor , Exasol , von , Github , installiert , werden , kann, library, (, devtools, ), install_github, (, ""EXASOL/r-exasol"", ), #Laden der übrigen Pakete, library, (, RODBC, ), library, (, rredis, ), library, (, exasol, ), library, (, stringi, ), library, (, magrittr, ), library, (, rpart, ), library, (, partykit, ), , R, # Erstellen des Verbindungsobjekts, con,  , &amp;, lt, ;,  , -,  , odbcConnect, (, ""exasol_vm"", ), # Verbinden mit Redis, redisConnect, (, ""172.20.248.13"", ), A,  , &amp;, lt, ;, -,  , 2, # Speichern von A in Redis, redisSet, (, ""Test"", ,,  , A, ), # Entfernen von A , rm, (, A, ), # Wenn der Wert 2 angezeigt wird, steht die Verbindung zu Redis , redisGet, (, ""Test"", ),  - Beitrag vom 13.05.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/old/r-und-exasol-installation-und-konfiguration-der-benoetigten-komponenten-2;EODA;
18.03.2016;CeBIT 2016: Data Science ist in den Unternehmen angekommen;, ×,  - Beitrag vom 18.03.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/cebit-2016-data-science-ist-in-den-unternehmen-angekommen;EODA;
26.02.2016;eoda erschließt R für den professionellen Einsatz im Unternehmen;, ×,  - Beitrag vom 26.02.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-erschliesst-r-fuer-den-professionellen-einsatz-im-unternehmen;EODA;
11.02.2016;Performantes Machine Learning mit R und H2O;, ×,  - Beitrag vom 11.02.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/performantes-machine-learning-mit-r-und-h2o;EODA;
02.02.2016;R Kenntnis Tage 2016: Mit R und Analytik die digitale Transformation meistern;, ×,  - Beitrag vom 02.02.2016, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/r-kenntnis-tage-2016-mit-r-und-analytik-die-digitale-transformation-meistern;EODA;
30.10.2015;Kasseler useR Group: Meetup im November zum Thema „Datenanalyse mit R“;, ×,  - Beitrag vom 30.10.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/kasseler-user-group-meetup-im-november-zum-thema-datenanalyse-mit-r;EODA;
07.10.2015;Eine gelungene Veranstaltung: Die R Kenntnis-Tage 2015;, ×,  - Beitrag vom 07.10.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eine-gelungene-veranstaltung-die-r-kenntnis-tage-2015;EODA;
23.09.2015;Die Kasseler useR Group – Data Science und Networking;, ×,  - Beitrag vom 23.09.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-kasseler-user-group-data-science-und-networking;EODA;
10.09.2015;Data Science mit R – Wissen vernetzen auf den R Kenntnis-Tagen 2015;, ×,  - Beitrag vom 10.09.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-science-mit-r-wissen-vernetzen-auf-den-r-kenntnis-tagen-2015;EODA;
11.08.2015;Von SPSS zu R: eoda bietet Assessment für wechselwillige SPSS-User;, ×,  - Beitrag vom 11.08.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/von-spss-zu-r-eoda-bietet-assessment-fuer-wechselwillige-spss-user;EODA;
14.07.2015;eoda auf der useR! Conference 2015 in Aalborg: Ein Resümee;, ×,  - Beitrag vom 14.07.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2015-in-aalborg-ein-resuemee;EODA;
07.07.2015;eoda auf der useR! Conference 2015 in Aalborg: Das Wichtigste vom zweiten Präsentationstag – Teil 2;, ×,  - Beitrag vom 07.07.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2015-in-aalborg-das-wichtigste-vom-zweiten-praesentationstag-teil-2;EODA;
06.07.2015;eoda auf der useR! Conference  2015 in Aalborg: Das Wichtigste vom zweiten Präsentationstag – Teil 1;, ×,  - Beitrag vom 06.07.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2015-in-aalborg-das-wichtigste-vom-zweiten-praesentationstag-teil-1;EODA;
03.07.2015;eoda auf der useR! Conference 2015 in Aalborg: Die Highlights vom ersten Präsentationstag – Teil 2;, ×,  - Beitrag vom 03.07.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2015-in-aalborg-die-highlights-vom-ersten-praesentationstag-teil-2;EODA;
02.07.2015;eoda auf der useR! Conference 2015 in Aalborg: Die Highlights vom ersten Präsentationstag – Teil 1;, ×,  - Beitrag vom 02.07.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2015-in-aalborg-die-highlights-vom-ersten-praesentationstag-teil-1;EODA;
01.07.2015;eoda auf der useR! Conference 2015 in Aalborg: Die Eindrücke vom „Tutorial Tuesday“;, ×,  - Beitrag vom 01.07.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-user-conference-2015-in-aalborg-die-eindruecke-vom-tutorial-tuesday;EODA;
26.06.2015;Die useR! Conference 2015 in Aalborg: Ausblick auf die Themen und Highlights;, ×,  - Beitrag vom 26.06.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-user-conference-2015-in-aalborg-ausblick-auf-themen-und-highlights;EODA;
07.05.2015;Pressemeldung – Data Mining meets Database: eoda und EXASOL beschließen Partnerschaft;, ×,  - Beitrag vom 07.05.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/pressemeldung-data-mining-meets-database-eoda-und-exasol-beschliessen-partnerschaft;EODA;
27.03.2015;Pressemitteilung: #dagehtwas – Datenanalyst eoda unterstützt die MT Melsungen bei umfassender Imageanalyse;, ×,  - Beitrag vom 27.03.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/pressemitteilung-dagehtwas-datenanalyst-eoda-unterstuetzt-die-mt-melsungen-bei-umfassender-imageanalyse;EODA;
27.01.2015;Pressemitteilung: Microsoft übernimmt den Open Source R-Spezialisten Revolution Analytics;, ×,  - Beitrag vom 27.01.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/microsoft-uebernimmt-den-open-source-r-spezialisten-revolution-analytics;EODA;
16.01.2015;Design of Experiments mit R als Fundament für richtige Entscheidungen;, ×,  - Beitrag vom 16.01.2015, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/design-of-experiments-mit-r-als-fundament-fuer-richtige-entscheidungen;EODA;
23.10.2014;eoda vertreibt RStudio-Produkte in Europa und unterstützt Anwender mit Beratung und Training.;, ×,  - Beitrag vom 23.10.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-vertreibt-rstudio-produkte-in-europa-und-unterstuetzt-anwender-mit-beratung-und-training;EODA;
22.10.2014;translate2R: SPSS Skripte auf Knopfdruck nach R migrieren;, ×,  - Beitrag vom 22.10.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/translate2r-spss-skripte-auf-knopfdruck-nach-r-migrieren;EODA;
08.10.2014;Statistische Prozesskontrolle als Grundlage optimalen Qualitätsmanagements;, ×,  - Beitrag vom 08.10.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/statistische-prozesskontrolle-als-grundlage-optimalen-qualitaetsmanagements;EODA;
05.09.2014;tableR vereinfacht die Prozesse von Marktforschern und Analysten;, ×,  - Beitrag vom 05.09.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/tabler-vereinfacht-die-prozesse-von-marktforschern-und-analysten;EODA;
15.08.2014;Survival-Analyse mit R als Fundament für Entscheidungen in Produktion und Vertrieb;, ×,  - Beitrag vom 15.08.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/survival-analyse-mit-r-als-fundament-fuer-entscheidungen-in-produktion-und-vertrieb;EODA;
02.07.2014;eoda stellt einen Service zur automatischen Übersetzung von SPSS® nach R vor;, ×,  - Beitrag vom 02.07.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-stellt-einen-service-zur-automatischen-uebersetzung-von-spss-nach-r-vor;EODA;
02.06.2014;Be data driven: Der Unterschied zwischen Kreisklasse und Weltklasse?;, ×,  - Beitrag vom 02.06.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/be-data-driven-der-unterschied-zwischen-kreisklasse-und-weltklasse;EODA;
27.04.2014;Der Data Scientist als das Bindeglied zwischen Big Data und Big Business;, ×,  - Beitrag vom 27.04.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/der-data-scientist-als-das-bindeglied-zwischen-big-data-und-big-business;EODA;
27.02.2014;Predictive Maintenance mit R;, ×,  - Beitrag vom 27.02.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/whitepaper-zu-predictive-maintenance-mit-r;EODA;
19.02.2014;Mit R intuitiv und professionell Software für Data Mining entwickeln – Besuchen Sie die eoda Data Science Trainings;, ×,  - Beitrag vom 19.02.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/mit-r-intuitiv-und-professionell-software-fuer-data-mining-entwickeln-training-in-der-r-akademie;EODA;
07.02.2014;Die Lesbarkeit von Texten berechnen – der Flesch Index als ein Baustein von Text Mining Anwendungen;, ×,  - Beitrag vom 07.02.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-lesbarkeit-von-texten-berechnen-der-flesch-index-als-ein-baustein-von-text-mining-anwendungen;EODA;
22.01.2014;Text Mining zur Prognose der Strompreisentwicklung;, ×,  - Beitrag vom 22.01.2014, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/text-mining-zur-prognose-der-strompreisentwicklung;EODA;
13.11.2013;Visual debugging mit R – Eine kurze Einführung zur Fehlerdiagnose mit StatET und RStudio;, ×, debug(), browser(), source(), .GlobalEnv, bar(), where, browser(expr), if(expr) debugonce(fun),  - Beitrag vom 13.11.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/visual-debugging-mit-r-eine-kurze-einfuehrung-zur-fehlerdiagnose-mit-statet-und-rstudio;EODA;
11.09.2013;Papierbasierte Prozesse im Personalwesen mit SAP integrieren;, ×,  - Beitrag vom 11.09.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/papierbasierte-prozesse-im-personalwesen-mit-sap-integrieren;EODA;
09.09.2013;eoda offers courses for data visualization and graphics with R;, ×,  - Beitrag vom 09.09.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-offers-courses-for-data-visualization-and-graphics-with-r-2;EODA;
30.08.2013;NoSQL-Datenbanken – Das Wichtigste in Kürze;, ×,  - Beitrag vom 30.08.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/nosql-datenbanken-das-wichtigste-in-kuerze;EODA;
28.08.2013;eoda erweitert Jaspersoft Business Intelligence Lösungen um Data Mining und Predictive Analytics mit R;, ×,  - Beitrag vom 28.08.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-erweitert-jaspersoft-business-intelligence-loesungen-um-data-mining-und-predictive-analytics-mit-r;EODA;
01.08.2013;eoda integriert analytische Services mit Talend;, ×,  - Beitrag vom 01.08.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-integriert-big-data-in-analytischen-services-mit-talend;EODA;
18.07.2018;Die Warenkorbanalyse: Das richtige Angebot für die richtige Kundengruppe zur richtigen Zeit am richtigen Platz;, ×,  - Beitrag vom 18.07.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-warenkorbanalyse-das-richtige-angebot-fur-die-richtige-kundengruppe-zur-richtigen-zeit-am-richtigen-patz;EODA;
10.07.2013;eoda auf der userR! Konferenz 2013 in Albacete – Eindrücke vom ersten Präsentationstag;, ×,  - Beitrag vom 10.07.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-auf-der-userr-konferenz-2013-in-albacete-eindrucke-vom-ersten-prasentationstag;EODA;
10.07.2013;R-Skripte durch C++ Integration mit Rcpp für Big Data optimieren;, ×,  - Beitrag vom 10.07.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/c-integration-mit-rcpp-zur-optimierung-von-r-skripten;EODA;
18.06.2013;R in der statistischen Prozesskontrolle – Möglichkeiten und Vorteile;, ×,  - Beitrag vom 18.06.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/r-in-der-statistischen-prozesskontrolle-moglichkeiten-und-vorteile;EODA;
18.06.2013;Statistische Prozesskontrolle als Potentialfaktor in Industrie und Logistik;, ×,  - Beitrag vom 18.06.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/statistische-prozesskontrolle-als-potentialfaktor-in-industrie-und-logistik;EODA;
04.06.2013;eoda bietet Lösungen zu Data Quality, Data Mining und Predictive Analytics für Salesforce-Anwender;, ×,  - Beitrag vom 04.06.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-bietet-losungen-zu-data-quality-data-mining-und-predictive-analytics-fur-salesforce-anwender;EODA;
03.06.2013;Predictive Maintenance –  Vorausschauendes Instandhalten mittels intelligenter Datenanalyse als Werttreiber in der Industrie;, ×,  - Beitrag vom 03.06.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/predictive-maintenance;EODA;
22.05.2013;(line.)profiling mit Rprof + R.3.x  – Performance von R-Skripten optimieren;, ×,  - Beitrag vom 22.05.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/profiling-mit-rprof-r-3-x;EODA;
16.05.2013;Ganzheitliches Kampagnenmanagement mit optimizeR;, ×,  - Beitrag vom 16.05.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/ganzheitliches-kampagnenmanagement-mit-optimizer;EODA;
02.05.2013;SAS hat einen neuen Vergleich von SAS und R veröffentlicht;, ×,  - Beitrag vom 02.05.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/sas-hat-einen-neuen-vergleich-von-sas-und-r-veroffentlicht;EODA;
19.04.2013;Revolution R Enterprise 6.2 mit neuen Funktionen für hoch performante Analysen auf Big Data;, ×, High Speed Teradata Connector, Parallel Random Number Generation, Fast Fixed Format Text Data Source, By-Group Summary Statistics, Stepwise Linear Regression für „Big-Data“-Modelle, Ausblick auf Revolution R Enterprise Release 7,  - Beitrag vom 19.04.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/revolution-r-enterprise-6-2-mit-neuen-funktionen-fur-hoch-performante-analysen-auf-big-data;EODA;
11.04.2013;Möglichkeiten und Vorteile von R in der Optimierung;, ×,  - Beitrag vom 11.04.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/moglichkeiten-und-vorteile-von-r-in-der-optimierung;EODA;
04.04.2013;R Version 3.0.0 ist da und bringt weitere Verbesserungen für Big Data;, ×,  - Beitrag vom 04.04.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/r-version-3-0-0-ist-da-und-bringt-weitere-verbesserungen-fur-big-data;EODA;
13.02.2013;Predictive Analytics mit Hilfe von Random Forest am Beispiel einer Win-Loss-Analyse;, ×,  - Beitrag vom 13.02.2013, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/predictive-analytics-mit-hilfe-von-random-forrest-am-beispiel-einer-win-loss-analyse;EODA;
06.12.2012;Big Data auf Hadoop mit R analysieren;, ×,  - Beitrag vom 06.12.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/bigdata-auf-hadoop-mit-r-analysieren;EODA;
30.11.2012;Eine kurze Geschichte über R;, ×,  - Beitrag vom 30.11.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eine-kurze-geschichte-uber-r;EODA;
23.11.2012;Die Shapley Value Regression in der Kundenzufriedenheitsanalyse;, ×,  - Beitrag vom 23.11.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-shapley-value-regression-in-der-kundenzufriedenheitsanalyse;EODA;
15.10.2012;Data Mining mit R;, ×,  - Beitrag vom 15.10.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/data-mining-mit-r;EODA;
11.09.2012;fuzzychekC – Erkennung von ähnlichen Daten;, ×,  - Beitrag vom 11.09.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/fuzzychekc-erkennung-von-ahnlichen-daten;EODA;
06.07.2012;Datamining mit R am Beispiel Zugmonitor;, ×,  - Beitrag vom 06.07.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/datamining-mit-r-am-beispiel-zugmonitor;EODA;
02.05.2012;R ist eines der wichtigsten Werkzeuge im Daten Journalismus;, ×,  - Beitrag vom 02.05.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/r-ist-eines-der-wichtigsten-werkzeuge-im-daten-journalismus;EODA;
13.04.2012;Excel Reports mit R erstellen am Beispiel des Zugmonitors der SZ;, ×,  - Beitrag vom 13.04.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/excel-reports-mit-r-erstellen-am-beispiel-des-zugmonitors-der-sz;EODA;
16.03.2012;Webbasierte Business Anwendungen mit R zur Visualisierung von Social Media Analysen;, ×,  - Beitrag vom 16.03.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/webbasierte-business-anwendungen-mit-r-zur-visualisierung-von-social-media-analysen;EODA;
13.03.2012;Die Schwarmintelligenz im Unternehmenseinsatz – Chancen und Risiken;, ×,  - Beitrag vom 13.03.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-schwarmintelligenz-im-unternehmenseinsatz-chancen-und-risiken;EODA;
02.03.2012;Die Anatomie eines „Twitter-Gesprächs“ – Social Media mir R analysieren;, ×,  - Beitrag vom 02.03.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-anatomie-eines-twitter-gesprachs-social-media-mir-r-analysieren;EODA;
18.02.2012;Geodatenanalyse und -visualisierung mit R;, ×,  - Beitrag vom 18.02.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/geodatenanalyse-und-visualisierung-mit-r;EODA;
27.01.2012;Beispiele für Big Data – „real world cases“;, ×,  - Beitrag vom 27.01.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/beispiele-fur-big-data-real-world-cases;EODA;
18.01.2012;Möglichkeiten der Datenvisualisierung mit R;", ×, , R, ###############################################################################################################, # Profilliniendiagramm., # Jede Profillinie wird per Koordinaten gezeichnet, d.h. jeder Mittelwert wird mit dazugehörigem y-Wert angebeben, # xlim und ylim geben die Größe der Grafik vor bzw. das Koordinatensystem, plot, (, x,  , =,  , c, (, 1, :, 1, ), ,,  , type, =, ""n"", ,,  , ylim, =, c, (, 1, ,, 10, ), ,, xlim, =, c, (, 1, ,, 5, ), ,,  , frame, ., plot, =, F, ,,  , xlab, =, """", ,,  , ylab, =, """", ,,  , yaxt, =, ""n"", ,,  , xaxt, =, ""n"", ,,  , main, =, ""Bewertung der Marken XYZ hinsichtlich folgender Merkmale"", ,,  , fg, =, ""blue"", ), # Einzeichnen der horizontalen und vertikalen Hilfslinien, vorher festlegen der Range von x und y, y, , R, # Waterfallchart by eoda, # Einbinden der notwendigen Pakete, library, (, ggplot2, ), # Historische Tagesgeld-Zinsen von der Budensbank einlesen, Tagesgeld,  , =,  , read, ., csv, (, ""http://www.bundesbank.de/statistik/statistik_zeitreihen_download.php?func=directcsv&amp;ampampfrom=&amp;ampampuntil=&amp;ampampfilename=bbk_SU0101&amp;ampampcsvformat=de&amp;ampampeuro=mixed&amp;ampamptr=SU0101"", ,,  , sep,  , =,  , "";"", ,,  , head, =, TRUE, ), # Rohdaten aufbereiten, Tagesgeld0, ,,  , ""Plus"", ,,  , ""Minus"", ), Agg, , 1, ,, 8, ,  - Beitrag vom 18.01.2012, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/old/moglichkeiten-der-datenvisualisierung-mit-r;EODA;
15.12.2011;Über R – Das Potenzial der Datenanalyse-Software;, ×,  - Beitrag vom 15.12.2011, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/uber-r-das-potenzial-der-datenanalyse-software;EODA;
23.11.2011;R-Akademie wird sehr gut bewertet;, ×,  - Beitrag vom 23.11.2011, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/r-akademie-bei-eoda-in-kassel-wird-sehr-gut-bewertet;EODA;
16.11.2011;Enterprise Wiki + Business Intelligence = Sales empowerment;, ×,  - Beitrag vom 16.11.2011, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/enterprise-wiki-business-intelligence-sales-empowerment;EODA;
04.11.2011;R entwickelt sich mehr und mehr zur Lingua franca für Big Data;, ×,  - Beitrag vom 04.11.2011, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/die-bedeutung-von-r-als-lingua-franca-fur-big-data-nimmt-weiter-zu;EODA;
25.08.2011;Highlights der useR! Konferenz 2011;, ×,  - Beitrag vom 25.08.2011, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/highlights-der-user-konferenz-2011;EODA;
03.06.2011;Reporting Services mit R;, ×,  - Beitrag vom 03.06.2011, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/reporting-services-mit-r;EODA;
26.10.2010;Analytisches CRM – ein Potenzialcheck;, ×,  - Beitrag vom 26.10.2010, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/crm-potenzialcheck;EODA;
07.09.2010;Kasseler useR-Group gegründet;, ×,  - Beitrag vom 07.09.2010, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/kasseler-user-group-gegrundet;EODA;
02.07.2010;eoda unterstützt als erstes deutsches Unternehmen die R-Foundation;, ×,  - Beitrag vom 02.07.2010, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/old/eoda-unterstutzt-als-erstes-deutsches-unternehmen-die-r-foundation;EODA;
18.12.2020;Von Wichteln und Algorithmen: Die Geschichte vom Weihnachtsmann;, ×,  - Beitrag vom 18.12.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/von-wichteln-und-algorithmen-die-geschichte-vom-weihnachtsmann;EODA;
15.12.2020;Data Science Trends 2021;, ×, Trends, automatisieren ,  - Beitrag vom 15.12.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-trends-2021;EODA;
24.09.2020;Was ist Augmented Analytics – Chancen für Unternehmen;, ×,  - Beitrag vom 24.09.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/augmented-analytics-chancen;EODA;
26.08.2020;AutoML in der Praxis: Mit YUNA elements ML-Skripte optimal steuern;, ×, YUNA elements,  - Beitrag vom 26.08.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/automl-yuna-elements;EODA;
20.08.2020;Plan/Apply/Destroy: Cloud-Infrastrukturen mit Terraform - Teil 1;, ×, Cloud-Infrastrukturen, Terraform, Konzept, Arbeitsweise,  - Beitrag vom 20.08.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/plan-apply-destroy-cloud-infrastrukturen-mit-terraform-teil-1;EODA;
13.08.2020;Data Science Framework – YUNA elements jetzt zum Download;, ×,  - Beitrag vom 13.08.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-framework-yuna-elements-jetzt-zum-download;EODA;
12.08.2020;Was ist AutoML? Hintergründe, Vorteile und Tools;, ×, AutoML?,  - Beitrag vom 12.08.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/was-ist-automl-hintergruende-vorteile-und-tools;EODA;
30.06.2020;Was ist ein Data Lake? – Eigenschaften und Vorteile;, ×, Data Lake?,  - Beitrag vom 30.06.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/was-ist-ein-data-lake;EODA;
18.06.2020;Out now: YUNA elements vereinfacht das Betreiben von Datenprodukten;, ×,  - Beitrag vom 18.06.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-software-yuna-elements;EODA;
09.06.2020;Use Cases von Data Science und KI im Maschinenbau - Teil 2;, ×, Maschinenbau, Um bei tausenden Bauteilen kurze Reaktionszeiten und schnelle Lieferungen zu ermöglichen, braucht es eine hohe Ersatzteilverfügbarkeit, . Genau hier gilt es Out-, of, -Stock-Situationen zu vermeiden, gleichzeitig aber auch die Kapitalbindung im Lager möglichst gering zu halten., Eine manuelle Optimierung der Lagerhaltung ist ab einem bestimmten Sortimentsumfang, nur schwer möglich, . Algorithmen helfen die Warenbeschaffung zu automatisieren und deutlich mehr relevante Einflussgrößen einzubeziehen. Saisonale Schwankungen, Trends oder bekannte Nutzungszyklen von bestimmten Teilen: Durch die Verbindung unterschiedlicher Kennzahlen und Einflussgrößen lässt sich der zukünftige, Bedarf, prognostizieren. Gleichzeitig hilft eine Analyse der jeweils notwendigen Wiederbeschaffungszeiten den richtigen Bestellzeitpunkt zu finden., , Die Verfügbarkeit von Rohstoffen ist die unverzichtbare Grundlage für eine funktionierende Produktion. Die Zeiten in denen Rohstoffe unbegrenzt und zu vergleichsweise konstanten Konditionen verfügbar waren sind aber vorbei. Starke neue Marktteilnehmer wie China oder Finanzinvestoren treten immer stärker in den Markt ein und erschweren die Bedingungen beim Rohstoffeinkauf. Mit Zeitreihen- und, Machine, -Learning-Algorithmen können Preisentwicklungen von Rohstoffen prognostiziert und optimale Beschaffungszeitpunkte leichter gefunden werden., Die, möglichen relevanten Datenquellen reichen von, der historischen Preisentwicklung der Rohstoffe über Nachrichtenmeldungen bis hin zu Branchenindizes und Währungskursen., , Auch im Bereich der Angebotserstellung und Kundenbetreuung lassen sich mit Data Science Prozesse im Maschinenbau optimieren., Ein möglicher Use Case betrifft die Hit Rate – also die Erfolgsquote – von unterbreiteten Angeboten. Diese prognostizieren zu können ist insbesondere im Maschinenbau von großer Bedeutung. Denn besonders hier im Bereich umfangreicher Industrieanlagen mit individuellen Modifikationen oder kompletter Individualentwicklungen ist die Angebotserstellung besonders komplex und aufwändig. Gelingt es die Hit Rate verlässlich zu prognostizieren, ,, lässt sich der investierte Aufwand für die Angebotserstellung besser steuern, und, Ressourcen effektiver nutzen. Auch hier bedienen sich die Prognosemodelle unterschiedlicher Einflussgrößen, wie, wirtschaftlichen Kennzahlen, des interessierten Unternehmens, Branchenindizes oder der Hit Rate zurückliegender Angebote., Ein weiterer Mehrwert dieses Use Cases: Die Verlässlichkeit der Umsatzplanung lässt sich ebenfalls erhöhen., , Mit welchem Produkt lassen sich bestehende Kunden am besten ansprechen? Welche Leistung ist die passendste im Hinblick auf die bereits gekauften Produkte und Services?, CRM-Daten können hier Aufschluss geben., Analytisch, basierend, auf Warenkorb- bzw. Assoziationsanalysen, werden im historischen Kaufverhalten der Kunden, analysiert,, um Sets an zusammengehörigen Produkten zu identifizieren., Auch kann im Hinblick auf den Vertrieb eines bestimmten Produktes oder Services ein Scoring der Bestandskunden vorgenommen werden, um die erwartete Attraktivität der entsprechenden Leistung für den jeweiligen Kunden zu bewerten. Dieses Scoring ist die belastbare Grundlage, um Prioritäten zu setzen und die Responsequote von Vertriebsaktivitäten zu steigern., , Erwarteter wirtschaftlicher Nutzen, analytische Komplexität, bestehende Datenlage: Der Ausgangspunkt von Data-Science-Projekten ist die Identifikation des richtigen Anwendungsfalls. Ist dieser gefunden, gilt es die Roadmap für die Realisierung zu entwickeln., , Während des, Prototypings, wird aus der Idee eine erlebbare Lösung, die bereits konkrete Mehrwerte stiftet und Gegenstand für wertvolles Feedback der Nutzer ist. In dieser Phase wird die Datenbasis geschaffen und die prototypische Variante des Algorithmus, entwickelt, ., , , Der erfolgreiche Prototyp kann nach einer Testphase für den Produktivbetrieb, ausgebaut werden. Dabei wird der Algorithmus nahtlos in die relevanten Unternehmensprozesse und die bestehende IT-Umgebung integriert., , Als Data Science Spezialist unterstützen wir Sie über den gesamten Prozess und verwandeln Ihre Daten in Mehrwerte. Sprechen Sie uns sehr gerne an oder erfahren Sie noch mehr über unser, Projektangebot, ., ,  - Beitrag vom 09.06.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/use-cases-data-science-ki-maschinenbau-2;EODA;
04.06.2020;Use Cases von Data Science und KI im Maschinenbau - Teil 1;, ×, Maschinenbau, Von der Entwicklung und dem Betrieb der Maschinen, über die richtige Bevorratung von Ersatzteilen bis hin zur Koordination von, Vetriebsaktivitäten, :, Die Use Cases für den Einsatz von Data Science und KI im Maschinenbau, sind genauso vielfältig wie die daraus entstehenden Mehrwerte., , Auf Basis unsererüber zehnjährigen Erfahrungin der, Konzeption und, Realisierung vonAnalytik, p, rojektenim Maschinenbau für Unternehmen wie, TRUMPF, und, Schenck, Process, und dem engen Austausch mit dem VDMA und seinen Mitgliedern stellen wir Ihnen erfolgsversprechende Data Science Use Cases im Maschinenbau vor., , Predictive, Maintenance ist eine der Kernkomponenten der Industrie 4.0 und das omnipräsente Thema, wenn es um die sinnvolle Nutzung von Maschinendaten geht. Der Anspruch von, Predictive, Maintenance ist es, Maschinenstörungen vorherzusagen, bevor die Auswirkungen spürbar werden und ein ungeplanter Ausfall droht., Temperaturanstiege, Geräusch- und Vibrationsentwicklungen, , Schwingungen, oder die Entstehung von Streulicht in der Lasertechnik:, Die Indikatoren für drohende Störungen können ganz unterschiedlich sein., Algorithmen erkennen in diesem komplexen Umfeld Anomalien und können Prognosen über die Ausfallwahrscheinlichkeit von Bauteilen liefern., Mehr zum Thema, Predictive, Maintenance, finden Sie auch in unserem, Whitepaper, ., , Moderne Industrieanlagen verfügen über eine Vielzahl an einstellbaren Parametern., Die optimale Konfiguration dieser Parameter unterliegt unterschiedlichen Einflussfaktoren, wie dem benötigten Output, den eingesetzten Rohstoffen oder äußeren Einflüssen, wie der Temperatur in der Fertigungshalle., Stets die optimalen Maschineneinstellungen zu finden ist aufwändig und erfordert eine hohe Kompetenz der Maschinenführer. Eine falsche Maschineneinstellung kann sich negativ auf die Produktqualität und damit auch auf die Zufriedenheit der Anlagenbetreiber mit der eingesetzten Maschine auswirken. Mittels Data Science lassen sich automatisiert Konfigurationsvorschläge ermitteln, die den Maschinenführern die Arbeit erleichtern und den optimalen Betrieb der Maschine ermöglichen., Konkret können Nachjustierungsaufwände durch den Bediener aufgrund einer ungünstigen initialen Konfiguration minimiert werden – der Produktionsprozess verläuft stabiler., Die Produktqualität bleibt unabhängig vom Maschinenführer konstant hoch., D, ie, , Bedienbarkeit, der Maschinen wird deutlich leichter und die Einarbeitungszeiten kürz, er, ., , Dieses Assistenzsystem basiert auf einem, Machine, -Learning-Algorithmus, der in einer Trainingsphase auf historischen Maschinendaten lernt, wie sich Prozessparameter auf die Qualität des Outputs auswirken., In diesen Lernprozess können auch die Rückmeldungen der Maschinenführer einbezogen werden., , , Neben der erzielten Produktqualität sind die Produktionskosten die entscheidende Kennzahl bei der Auswahl der richtigen Maschinenkonfiguration., Um für den jeweiligen Anlagenbetreiber die optimale Konfiguration zu finden, ist es, zum Beispiel wichtig, auch regionale Eigenheiten des Betriebsstandorts einzubeziehen. Gerade die Kunden international agierender Maschinenbauer unterliegen sehr unterschiedlichen Kostenstrukturen., Besonders, Energiekosten, oder additive Kosten, unterscheiden sich, teilweise, gravierend, . Diese externen Informationen können in das Analysemodell zur optimalen Maschinenkonfiguration eingebunden werden. Das Assistenzsystem empfiehlt dem Maschinenführer die Konfiguration, mit den an diesem Standort geringsten Produktionskosten., , Das Qualitätsmanagement ist ein weiteres zentrales Anwendungsgebiet von Data Science in der Industrie 4.0., Ein immer wichtiger werdender Baustein davon ist die Bilddatenanalyse. Mittels Bilderkennungsalgorithmen kann die Qualitätsüberwachung stärker automatisiert werden. Dadurch gelingt es flächendeckender zu prüfen und schneller auf Qualitätsschwankungen des Outputs aufmerksam zu werden. Konkret können zum Beispiel erzeugte Schweißnähte per Bild erfasst und automatisiert analysiert werden. Die Erkennung unzureichender Schweißnähte kann dann eine Warnung an den Fachexperten auslösen. Durch dieses zweistufige Vorgehen bleibt die Entscheidungskompetenz beim Menschen und der Algorithmus kann mit den Rückmeldungen der Experten weiter trainiert werden. Ein analoges Beispiel findet sich in der Medizin, wo Bilddatenanalysen bereits erfolgreich zur Erkennung von Krebserkrankungen auf Untersuchungsaufnahmen, eingesetzt werden, ., , Erwarteter wirtschaftlicher Nutzen, analytische Komplexität, bestehende Datenlage: Der Ausgangspunkt von Data-Science-Projekten ist die Identifikation des richtigen Anwendungsfalls. Ist dieser gefunden, gilt es die Roadmap für die Realisierung zu entwickeln., , Während des, Prototypings, wird aus der Idee eine erlebbare Lösung, die bereits konkrete Mehrwerte stiftet und Gegenstand für wertvolles Feedback der Nutzer ist. In dieser Phase wird die Datenbasis geschaffen und die prototypische Variante des Algorithmus, entwickelt, ., , , Der erfolgreiche Prototyp kann nach einer Testphase für den Produktivbetrieb, ausgebaut werden. Dabei wird der Algorithmus nahtlos in die relevanten Unternehmensprozesse und die bestehende IT-Umgebung integriert., , Als Data Science Spezialist unterstützen wir Sie über den gesamten Prozess und verwandeln Ihre Daten in Mehrwerte. Sprechen Sie uns sehr gerne an oder erfahren Sie noch mehr über unser, Projektangebot, ., ,  - Beitrag vom 04.06.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/use-cases-data-science-ki-im-maschinenbau-1;EODA;
27.05.2020;Daran kann’s liegen, wenn Data Science Projekte nicht erfolgreich sind;, ×,  - Beitrag vom 27.05.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/gruende-warum-data-science-projekte-nicht-immer-erfolgreich-sind-teil-1;EODA;
13.05.2020;Mit Data Science Kundenbewertungen besser nutzen;, ×, Kundenbewertungen,  - Beitrag vom 13.05.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/mit-data-science-kundenbewertungen-besser-nutzen;EODA;
06.05.2020;Was ist Federated Learning? Hintergründe und Anwendungsbeispiele;, ×,  - Beitrag vom 06.05.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/was-ist-federated-learning;EODA;
17.04.2020;Long short-term memory: Hintergründe und Best-Practice-Ansätze für LSTM;, ×, Long short-term memory:,  - Beitrag vom 17.04.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/long-short-term-memory-tutorial;EODA;
08.04.2020;Long short-term memory: Anwendungsbeispiele von LSTM im Unternehmen;, ×, Long short-term memory:,  - Beitrag vom 08.04.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/long-short-term-memory-anwendungsbeispiele-im-unternehmen;EODA;
02.04.2020;"""Data Science"" im Support - Eat your own dogfood";, ×, Vorname*, Nachname*, E-Mail*, Telefon*, Organisation*,  - Beitrag vom 02.04.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/data-science-im-support-eat-your-own-dogfood;EODA;
26.03.2020;Online R-Trainings: Data Science lernen - live und interaktiv;, ×, live und interaktiv, Wenn wegen, der Corona-Gefahr, Konzerte und Theateraufführungen abgesagt werden, Fitnessstudios schließen und, Büros nach Hause verlegt werden, muss man nicht komplett auf, “, Live-Events, ”, verzichten., Wohnzimmer-Konzerte, Online-Yoga- und Tanzkurse oder, Home, –, Office, -Möglichkeiten, –, diese Angebote gibt es bereits und auch wir bringen unsere Schulungen ins Internet., , Sie möchten trotz, Home, , Office, und eingeschränkter Reisemöglichkeiten an einer Schulung teilnehmen, die Sie wirklich weiter bringt?, , Dan, n, sind unsere, Online R-Trainings, genau das Richtige, !, , Gerade in der aktuellen Zeit zeigt sich, wie wichtig es ist, die Chancen der Digitalisierung zu nutzen. Aus diesem Grund bieten wir unsere beliebten Kurse „Einführung in R“ und „Machine Learning mit R“ , , an, um Ihnen das benötigte Wissen für den produktiven Einsatz von R vermitteln zu können., , Was unterscheidet unser Angebot von anderen Online-Trainings?, , Die Präsenz, unserer erfahrenen Data Science Trainer. Im direkten Austausch werden Ihre individuellen Fragen beantwortet – dadurch entsteht für Sie der größtmögliche Lernerfolg, mit Praxisnähe trotz des virtuellen Trainings!, , Unsere R-Schulungen sind das deutschsprachige Weiterbildungsprogramm für die Data-Science-Sprache R. Bereits über1.500 Teilnehmerinnenund Teilnehmer waren begeistert von der Praxiserfahrung unserer Trainer und dem Aufbau unserer Schulungen., , Key Facts, Ort:, Im, Home Office, , Büro oder vom Balkon aus: Unsere Trainings als Webinar bieten Ihnen die räumliche Flexibilität, die Sie in der aktuellen Situation benötigen., , Preis:, Pro Kurs: € 249,- | Im Bundle: € 399,-, , Einführung in R, Einführung in R, |, |, 21.04. – 22.04.2020 | 09:00 Uhr bis 13:00 Uhr, 21.04. – 22.04.2020 | 09:00 Uhr bis 13:00 Uhr, , Der Kurs versteht sich als Einführung in R und seine Grundfunktionalitäten und erleichtert Ihnen mit praktischen Tipps und Übungen den Einstieg in R. Dieser Grundkurs dient Ihnen als R-Einsteiger ohne tiefergehende Vorkenntnisse als Ausgangspunkt für den weiteren Einsatz von R in individuellen Anwendungsszenarien., , Ziel des Kurses ist es, Ihnen Logik und Terminologie der Programmiersprache R zu vermitteln und den Grundstein für ein selbständiges Arbeiten mit R zu legen., , Machine, Machine, Learning mit R, Learning mit R, |, |, 23.04. – 24.04.2020 | , 23.04. – 24.04.2020 | , 09:00 Uhr bis 13:00 Uhr, 09:00 Uhr bis 13:00 Uhr, , Nutzen SieMachineLearning und Data-Mining-Algorithmen, um auf Datenbasis Anwendungen der Künstlichen Intelligenz zu entwickeln., , In unserem Kurs „MachineLearning mit R“ geben wir Ihnen einen Einblick?in Algorithmen des maschinellen Lernens und zeigen Ihnen, wie Sie eigene Modelle entwickeln, welche Herausforderungen Ihnen begegnen und wie Sie diese meistern., , Anhand von praxisnahen Beispielen und Übungen vermitteln wir Ihnen die, Fähigkeiten, um, Machine, -Learning-Verfahren in R eigenständig umzusetzen. Die Aufbereitung der Daten, die Entwicklung und das Training von Algorithmen sowie die Validierung von Analysemodellen: In unserem Kurs lernen Sie die zentralen Schritte?des, Machine, Learning kennen., ,  - Beitrag vom 26.03.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/online-r-trainings-data-science-lernen-live-und-interaktiv;EODA;
24.03.2020;10 Gründe wie YUNA Ihre Data-Science-Projekte voranbringt;, ×, YUNA, Vorname*, Nachname*, E-Mail*, Telefon*, Organisation*,  - Beitrag vom 24.03.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/10-gruende-fuer-yuna;EODA;
19.03.2020;Shiny: Performance-Tuning mit future und promises – Die Theorie ;", ×, Shiny:, future &amp; promises, Shiny Workflow, Asynchrone Programmierung, Erfahren Sie mehr., Erfahren Sie mehr.,  - Beitrag vom 19.03.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden";https://www.eoda.de/wissen/blog/shiny-performance-tuning-mit-future-promises-die-theorie;EODA;
11.03.2020;Liebe Data Scientists - erleichtert euch die Arbeit!;, ×,  - Beitrag vom 11.03.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/liebe-data-scientists-erleichtert-euch-die-arbeit;EODA;
06.03.2020;Mit Data Science zu mehr Nachhaltigkeit im Unternehmen;, ×, Nachhaltigkeit,  - Beitrag vom 06.03.2020, Hiermit erkläre ich mich mit der Datenschutzerklärung von eoda einverstanden;https://www.eoda.de/wissen/blog/mit-data-science-zu-mehr-nachhaltigkeit;EODA;
